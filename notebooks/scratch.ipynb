{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Lecture 2 - Python, Jupyter and APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 2.1 Jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --version\n",
    "%pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flask\n",
    "import flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "print(site.getsitepackages())\n",
    "!ls -l {site.getsitepackages()[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 2.3 API requests using `requests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import threading\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "tasks = {}\n",
    "i = 1\n",
    "\n",
    "@app.post(\"/tasks\")\n",
    "def create():\n",
    "    global i\n",
    "    if not request.json: abort(400)\n",
    "    t = {\"id\": i, \"state\": \"created\", \"data\": request.json}\n",
    "    tasks[i] = t\n",
    "    i += 1\n",
    "    return jsonify(t), 201\n",
    "\n",
    "# This starts Flask's blocking event loop in same thread as Jupyter\n",
    "# Subsequent cells can't run until Flask stops serving\n",
    "#app.run()\n",
    "\n",
    "# Inside a Jupyter notebook then, run Flask in a background process\n",
    "# `use_reloader = False` is mandatory in a Jupyter notebook\n",
    "def run():\n",
    "    app.run(host=\"127.0.0.1\", port=5000, use_reloader=False)\n",
    "threading.Thread(target=run, daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic test using curl\n",
    "!curl -X POST http://127.0.0.1:5000/tasks -H \"Content-Type: application/json\" -d '{\"type\": \"demo\", \"params\": {\"x\": 1}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.post(\n",
    "    \"http://127.0.0.1:5000/tasks\",\n",
    "    json={\"type\": \"demo\", \"params\": {\"x\": 1}}\n",
    ")\n",
    "print(r.status_code, r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, abort, request\n",
    "import threading\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "tasks = {}\n",
    "\n",
    "i = 1\n",
    "\n",
    "@app.post(\"/tasks\")\n",
    "def create():\n",
    "    global i\n",
    "    if not request.json: abort(400)\n",
    "    t = {\"id\": i, \"state\": \"created\", \"data\": request.json}\n",
    "    tasks[i] = t\n",
    "    i += 1\n",
    "    return jsonify(t), 201\n",
    "\n",
    "@app.get(\"/tasks\")\n",
    "def list_tasks():\n",
    "    return jsonify(list(tasks.values()))\n",
    "\n",
    "@app.get(\"/tasks/<int:i>\")\n",
    "def get_task(i):\n",
    "    return jsonify(tasks[i]) if i in tasks else abort(404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    app.run(host=\"127.0.0.1\", port=5000, use_reloader=False)\n",
    "threading.Thread(target=run, daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"http://127.0.0.1:5000/tasks\")\n",
    "print(r.status_code, r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.post(\n",
    "    \"http://127.0.0.1:5000/tasks\",\n",
    "    json={\"type\": \"demo\", \"params\": {\"x\": 1}}\n",
    ")\n",
    "print(r.status_code, r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.post(\n",
    "    \"http://127.0.0.1:5000/tasks\",\n",
    "    json={\"type\": \"demo\", \"params\": {\"x\": 1}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.post(\n",
    "    \"http://127.0.0.1:5000/tasks\",\n",
    "    json={\"type\": \"demo\", \"params\": {\"x\": 1}}\n",
    ").status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(\"http://127.0.0.1:5000/tasks\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(\"http://127.0.0.1:5000/tasks/2\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Lecture 3 - Visualising Fields and Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 3.2 ecCodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eccodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grib_ls -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eccodes.codes_get_api_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Read GRIB2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find .. -name \"*.grib2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "grib_file = \"../e-ai_ml2/course/code/code03/ifs_2t.grib2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(grib_file, \"rb\") as f:\n",
    "    while True:\n",
    "        gid = eccodes.codes_grib_new_from_file(f)\n",
    "        if gid is None: break\n",
    "\n",
    "        short = eccodes.codes_get(gid, \"shortName\")\n",
    "        level = eccodes.codes_get(gid, \"level\")\n",
    "        size  = eccodes.codes_get_size(gid, \"values\")\n",
    "\n",
    "        print(short, level, size)\n",
    "\n",
    "        eccodes.codes_release(gid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Download GRIB2 file from ECMWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecmwf.opendata import Client\n",
    "\n",
    "client = Client(\n",
    "    source = \"ecmwf\",\n",
    "    model = \"ifs\",\n",
    ")\n",
    "\n",
    "client.retrieve(\n",
    "    time = 0,\n",
    "    type = \"fc\",\n",
    "    step = 24,\n",
    "    param = [\"2t\", \"msl\"],\n",
    "    target = \"ifs_2t.grib2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.grib2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Download from DWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "base_url = \"http://opendata.dwd.de/weather/nwp/icon/grib/00/t_2m/\"\n",
    "now = datetime.datetime.now(datetime.UTC)\n",
    "filename = f\"icon_global_icosahedral_single-level_{now:%Y%m%d}00_000_T_2M.grib2.bz2\"\n",
    "url = base_url + filename\n",
    "grib_filename = filename[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "wget.download(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "\n",
    "with bz2.open(filename, \"rb\") as f_in, open(grib_filename, \"wb\") as f_out:\n",
    "    f_out.write(f_in.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.grib2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eccodes\n",
    "with open(grib_filename, \"rb\") as f:\n",
    "    while True:\n",
    "        gid = eccodes.codes_grib_new_from_file(f)\n",
    "        if gid is None: break\n",
    "\n",
    "        short = eccodes.codes_get(gid, \"shortName\")\n",
    "        level = eccodes.codes_get(gid, \"level\")\n",
    "        size  = eccodes.codes_get_size(gid, \"values\")\n",
    "\n",
    "        print(short, level, size)\n",
    "\n",
    "        eccodes.codes_release(gid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Extract and list metadata keys from a GRIB file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eccodes\n",
    "with open(grib_filename, \"rb\") as f:\n",
    "    while True:\n",
    "        gid = eccodes.codes_grib_new_from_file(f)\n",
    "        if gid is None: break\n",
    "\n",
    "        key_iterator = eccodes.codes_keys_iterator_new(gid)\n",
    "        keys = []\n",
    "\n",
    "        while eccodes.codes_keys_iterator_next(key_iterator):\n",
    "            keyname = eccodes.codes_keys_iterator_get_name(key_iterator)\n",
    "            if keyname not in ['section2Padding', 'codedValues', 'values']:\n",
    "                value = eccodes.codes_get_string(gid, keyname)\n",
    "            keys.append((keyname, value))\n",
    "\n",
    "        eccodes.codes_release(gid)\n",
    "\n",
    "        for key, value in keys:\n",
    "              print(f\"Key: {key:40} Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eccodes\n",
    "with open(grib_file, \"rb\") as f:\n",
    "    while True:\n",
    "        gid = eccodes.codes_grib_new_from_file(f)\n",
    "        if gid is None: break\n",
    "\n",
    "        key_iterator = eccodes.codes_keys_iterator_new(gid)\n",
    "        keys = []\n",
    "\n",
    "        while eccodes.codes_keys_iterator_next(key_iterator):\n",
    "            keyname = eccodes.codes_keys_iterator_get_name(key_iterator)\n",
    "            if keyname not in ['section2Padding', 'codedValues', 'values']:\n",
    "                value = eccodes.codes_get_string(gid, keyname)\n",
    "            keys.append((keyname, value))\n",
    "\n",
    "        eccodes.codes_release(gid)\n",
    "\n",
    "        for key, value in keys:\n",
    "              print(f\"Key: {key:40} Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cartopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(grib_file, \"rb\") as f:\n",
    "    # First message is pressure\n",
    "    gid = eccodes.codes_grib_new_from_file(f)\n",
    "\n",
    "nx = eccodes.codes_get(gid, \"Ni\")\n",
    "ny = eccodes.codes_get(gid, \"Nj\")\n",
    "values = eccodes.codes_get_array(gid, \"values\")\n",
    "#field = values.reshape(ny, nx)\n",
    "field = values.reshape(ny, nx) / 100.0  # Pa → hPa\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7, 3.5))\n",
    "#plt.imshow(field)\n",
    "im = plt.imshow(field)\n",
    "plt.title(\"IFS Mean Sea Level Pressure (hPa)\")\n",
    "plt.colorbar(im, label=\"Pressure (hPa)\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "import os\n",
    "out_dir = \"../assets/images\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, \"grib_plot_with_eccodes_ifs_pressure.png\")\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "!ls -ltr {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(grib_file, \"rb\") as f:\n",
    "    # Run twice to get the second message (T2m)\n",
    "    gid = eccodes.codes_grib_new_from_file(f)\n",
    "    gid = eccodes.codes_grib_new_from_file(f)\n",
    "\n",
    "nx = eccodes.codes_get(gid, \"Ni\")\n",
    "ny = eccodes.codes_get(gid, \"Nj\")\n",
    "values = eccodes.codes_get_array(gid, \"values\")\n",
    "field = values.reshape(ny, nx)\n",
    "\n",
    "plt.figure(figsize=(7, 3.5))\n",
    "#plt.imshow(field)\n",
    "im = plt.imshow(field)\n",
    "plt.title(\"IFS 2m Temperature (K)\")\n",
    "plt.colorbar(im, label=\"K\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "#plt.show()\n",
    "\n",
    "import os\n",
    "out_dir = \"../assets/images\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, \"grib_plot_with_eccodes_ifs_t2m.png\")\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "!ls -ltr {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "ax.coastlines()\n",
    "ax.add_feature(cfeature.BORDERS)\n",
    "\n",
    "lats   = eccodes.codes_get_array(gid, \"latitudes\")\n",
    "lons   = eccodes.codes_get_array(gid, \"longitudes\")\n",
    "lat   = lats.reshape(ny, nx)\n",
    "lon   = lons.reshape(ny, nx)\n",
    "\n",
    "ax.pcolormesh(lon, lat, field, transform=ccrs.PlateCarree(), cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install scipy\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "\n",
    "def load_grib(file, var):\n",
    "    \"\"\"Loads specified variable from GRIB file.\"\"\"\n",
    "    with open(file, 'rb') as f:\n",
    "        while (gid := eccodes.codes_grib_new_from_file(f)) is not None:\n",
    "            if eccodes.codes_get(gid, \"shortName\") == var:\n",
    "                vals = eccodes.codes_get_array(gid, \"values\")\n",
    "                eccodes.codes_release(gid)\n",
    "                return vals\n",
    "            eccodes.codes_release(gid)\n",
    "    return None\n",
    "\n",
    "def interpolate_to_grid(lat, lon, t2m, bbox, grid_res=0.25):\n",
    "    \"\"\"Interpolates T2M data onto a regular lat/lon grid.\"\"\"\n",
    "    latmin, latmax, lonmin, lonmax = bbox\n",
    "\n",
    "    # Define a smooth regular grid\n",
    "    grid_lat = np.arange(latmin, latmax, grid_res)\n",
    "    grid_lon = np.arange(lonmin, lonmax, grid_res)\n",
    "    lon_grid, lat_grid = np.meshgrid(grid_lon, grid_lat)\n",
    "\n",
    "    points = np.column_stack((lon.ravel(), lat.ravel()))\n",
    "    values = t2m.ravel()\n",
    "    xi = np.column_stack((lon_grid.ravel(), lat_grid.ravel()))\n",
    "    t2m_grid = griddata(points, values, xi, method='cubic')\n",
    "    t2m_grid = t2m_grid.reshape(lon_grid.shape)\n",
    "    \n",
    "    return lon_grid, lat_grid, t2m_grid\n",
    "\n",
    "\n",
    "def plot_t2m_grid(lat, lon, t2m, bbox, title, fname):\n",
    "    \"\"\"Plots interpolated 2m temperature as a smooth heatmap.\"\"\"\n",
    "    lon_grid, lat_grid, t2m_grid = interpolate_to_grid(lat, lon, t2m, bbox)\n",
    "\n",
    "    # Set reasonable aspect ratio based on bounding box size\n",
    "    lon_range = bbox[3] - bbox[2]\n",
    "    lat_range = bbox[1] - bbox[0]\n",
    "    aspect_ratio = lon_range / lat_range\n",
    "    figsize = (10, max(5, 10 / aspect_ratio))  # Maintain consistent width & prevent extreme height\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.set_extent([bbox[2], bbox[3], bbox[0], bbox[1]])\n",
    "    ax.add_feature(cfeature.LAND, edgecolor='black')\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "\n",
    "    # Use smooth interpolation and correct aspect ratio\n",
    "    img = ax.imshow(t2m_grid, extent=[bbox[2], bbox[3], bbox[0], bbox[1]], origin='lower',\n",
    "                    cmap='jet', transform=ccrs.PlateCarree(), aspect='auto', interpolation='bicubic')\n",
    "\n",
    "    plt.colorbar(img, label=\"Temperature (K)\")\n",
    "    plt.title(title)\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches='tight')  # Reduce DPI for smaller file size\n",
    "    #plt.show()\n",
    "\n",
    "import os\n",
    "out_dir = \"../assets/images\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "lat = load_grib(\"../e-ai_ml2/course/code/code03/icon_lat.grib\", \"tlat\")\n",
    "lon = load_grib(\"../e-ai_ml2/course/code/code03/icon_lon.grib\", \"tlon\")\n",
    "t2m = load_grib(\"../e-ai_ml2/course/code/code03/icon_t2m.grib\", \"2t\")\n",
    "\n",
    "# Plot interpolated global and Germany views\n",
    "out_path = os.path.join(out_dir, \"grib_plot_with_eccodes_icon_t2m_global_interp.png\")\n",
    "plot_t2m_grid(lat, lon, t2m, (-90, 90, -180, 180), \"ICON Interpolated Global 2m Temperature\", \"icon_t2m_global_interp.png\")\n",
    "out_path = os.path.join(out_dir, \"grib_plot_with_eccodes_icon_t2m_germany_interp.png\")\n",
    "plot_t2m_grid(lat, lon, t2m, (47, 55, 5, 15), \"ICON Interpolated 2m Temperature over Germany\", \"icon_t2m_germany_interp.png\")\n",
    "\n",
    "!ls -ltr {out_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## 3.3 Accessing SYNOP observation files from NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../e-ai_ml2 -name \"*.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install netCDF4\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "filename = \"../e-ai_ml2/course/code/code03/synop.nc\"\n",
    "\n",
    "ncfile = Dataset(filename, \"r\")\n",
    "\n",
    "lats = ncfile.variables[\"MLAH\"][:]\n",
    "lons = ncfile.variables[\"MLOH\"][:]\n",
    "temps = ncfile.variables[\"MTDBT\"][:]\n",
    "\n",
    "lats = np.array(lats)\n",
    "lons = np.array(lons)\n",
    "temps = np.array(temps)\n",
    "\n",
    "ncfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=1e+20\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "#projections = [[ccrs.PlateCarree(), \"PlateCarree\"]]\n",
    "projections=[[ccrs.PlateCarree(), \"PlateCarree\"], \n",
    "                                  [ccrs.TransverseMercator(), \"TransverseMercator\"],\n",
    "                                  [ccrs.Mercator(), \"Mercator\"],\n",
    "                                  [ccrs.EuroPP(), \"EuroPP\"],\n",
    "                                  [ccrs.Geostationary(), \"Geostationary\"],\n",
    "                                  [ccrs.Stereographic(), \"Stereographic\"]]\n",
    "# Filter out large missing values\n",
    "valid_mask = (temps < threshold) & np.isfinite(temps)\n",
    "lats, lons, temps = lats[valid_mask], lons[valid_mask], temps[valid_mask]\n",
    "\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "for projection in projections:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={'projection': projection[0]})\n",
    "        scatter = ax.scatter(lons, lats, c=temps, cmap='jet', s=5, alpha=0.7, transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Add map features\n",
    "        ax.coastlines()\n",
    "        ax.add_feature(cfeature.BORDERS, edgecolor='gray')\n",
    "        ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "\n",
    "        # Add colorbar with better spacing\n",
    "        cbar = plt.colorbar(scatter, ax=ax, fraction=0.04, pad=0.08)  \n",
    "        cbar.set_label(\"Temperature (K)\")\n",
    "\n",
    "        # Set title\n",
    "        plt.title(\"Temperature Observations on Map in Projection \" + projection[1])\n",
    "\n",
    "        # Save and show the plot\n",
    "        #plt.show()\n",
    "        import os\n",
    "        out_dir = \"../assets/images\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        out_path = os.path.join(out_dir, f\"synop_temp_{projection[1]}.png\")\n",
    "        plt.savefig(out_path, dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "        !ls -ltr {out_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "## 3.4 AIREP feedback files in NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "airep_file = \"../e-ai_ml2/course/code/code03/monAIREP.nc\"\n",
    "\n",
    "ncfile = Dataset(airep_file, \"r\")\n",
    "\n",
    "nc = 1\n",
    "for varname in ncfile.variables.keys():\n",
    "    var = ncfile.variables[varname]\n",
    "    description = getattr(var, \"longname\", \"N/A\")\n",
    "    dims = [len(ncfile.dimensions[dim]) for dim in var.dimensions]\n",
    "    shape1 = dims[0] if len (dims) > 0 else \"\"\n",
    "    shape2 = dims[1] if len (dims) > 1 else \"\"\n",
    "    print (\"{:<4} {:40} {:>10} {:>10} {:30}\".format(nc, varname, shape1, shape2, description))\n",
    "    if nc % 10 == 0:\n",
    "        print(\"-\" * 110)\n",
    "    nc += 1\n",
    "\n",
    "ncfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read header-level variables\n",
    "ncfile = Dataset(airep_file, \"r\")\n",
    "lat = ncfile.variables[\"lat\"][:]\n",
    "lon = ncfile.variables[\"lon\"][:]\n",
    "\n",
    "# Body-level variables\n",
    "varno_all = ncfile.variables[\"varno\"][:]\n",
    "obs_all = ncfile.variables[\"obs\"][:]\n",
    "l_body = ncfile.variables[\"l_body\"][:]\n",
    "\n",
    "# Expand lat/lon to match body-level observations\n",
    "ni = len(l_body)\n",
    "ie = np.repeat(range(0, ni), l_body)  # Map each body entry to its header index\n",
    "\n",
    "# varno == 2 is upper air temperature\n",
    "idx = np.where(varno_all == 2)[0]\n",
    "\n",
    "# Filter lat, lon, obs\n",
    "lat_filtered = lat[ie[idx]]\n",
    "lon_filtered = lon[ie[idx]]\n",
    "obs_filtered = obs_all[idx]\n",
    "\n",
    "var = \"level\"\n",
    "var_data = ncfile.variables[var][:]\n",
    "\n",
    "print(var_data.shape[0], len(varno_all))\n",
    "\n",
    "extra_data = var_data[idx]\n",
    "lats, lons, obs = lat_filtered, lon_filtered, obs_filtered\n",
    "heights = extra_data\n",
    "\n",
    "threshold=1e+20\n",
    "\n",
    "print(len(lats), \"Latitudes:\", lats[:5])\n",
    "print(len(lons), \"Longitudes:\", lons[:5])\n",
    "print(len(obs), \"Observations:\", obs[:5])\n",
    "if heights is not None:\n",
    "    print(len(heights), \"Heights:\", heights[:5])\n",
    "\n",
    "valid_mask = (obs < threshold) & np.isfinite(obs)\n",
    "lats, lons, obs = lats[valid_mask], lons[valid_mask], obs[valid_mask]\n",
    "\n",
    "# Keep only temperatures between -30°C and 40°C (243.15K to 313.15K)\n",
    "temp_min, temp_max = 180, 320\n",
    "physical_mask = (obs >= temp_min) & (obs <= temp_max)\n",
    "\n",
    "lats_filtered, lons_filtered, obs_filtered = lats[physical_mask], lons[physical_mask], obs[physical_mask]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "scatter = ax.scatter(lons_filtered, lats_filtered, c=obs_filtered, cmap='jet', s=2, alpha=0.7, transform=ccrs.PlateCarree())\n",
    "\n",
    "ax.coastlines()\n",
    "ax.add_feature(cfeature.BORDERS, edgecolor='gray')\n",
    "ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "\n",
    "# Ensure the colorbar does not exceed figure height\n",
    "cbar = fig.colorbar(scatter, ax=ax, orientation='vertical', fraction=0.04, pad=0.08, shrink=0.8)\n",
    "cbar.set_label(\"Temperature (K)\")\n",
    "\n",
    "plt.title(\"AIREP Observations\")\n",
    "#plt.show()\n",
    "import os\n",
    "out_dir = \"../assets/images\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, f\"airep.png\")\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "!ls -ltr {out_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## GPU access in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "d = torch.device(\"mps\")\n",
    "\n",
    "x = torch.rand((4000, 4000),device=d)\n",
    "\n",
    "t0 = time.time()\n",
    "y = torch.matmul(x, x)\n",
    "torch.mps.synchronize()\n",
    "print(\"Time = \", round(time.time()-t0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30000\n",
    "x0 = torch.rand((n, n), device=\"cpu\")\n",
    "x1 = torch.rand((n, n), device=\"cpu\")\n",
    "t0 = time.time()\n",
    "y0 = torch.matmul(x0, x0)\n",
    "y1 = torch.matmul(x1, x1)\n",
    "print(\"Time = \", round(time.time() - t0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = torch.device(\"mps:0\")\n",
    "d1 = torch.device(\"mps:1\")\n",
    "x0 = torch.rand((n, n), device=d0)\n",
    "x1 = torch.rand((n, n), device=d1)\n",
    "\n",
    "t0 = time.time()\n",
    "y0 = torch.matmul(x0, x0)\n",
    "y1 = torch.matmul(x1, x1)\n",
    "torch.mps.synchronize()\n",
    "\n",
    "print(\"Time = \", round(time.time() - t0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, x1, y0, y1, x, y = 0, 0, 0, 0, 0, 0\n",
    "\n",
    "A0 = torch.rand((n//2,n), device=d0)\n",
    "A1 = torch.rand((n//2,n), device=d1)\n",
    "\n",
    "B = torch.rand((n,n), device=d0)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "C0 = A0 @ B\n",
    "C1 = A1 @ B.to(d1)\n",
    "\n",
    "torch.mps.synchronize()\n",
    "\n",
    "print(\"Time = \", round(time.time() - t0, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### Mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.device(\"mps\")\n",
    "\n",
    "def doit(d):\n",
    "    x = torch.randn((20000, 1024), device=d)\n",
    "    W1 = torch.randn((1024, 4096), device=d)\n",
    "    W2 = torch.randn((4096, 1024), device=d)\n",
    "    t0 = time.time()\n",
    "    y = torch.nn.functional.gelu(x @ W1)\n",
    "    z = y @ W2\n",
    "    torch.mps.synchronize()\n",
    "    return round(time.time() - t0, 3)\n",
    "\n",
    "for dt in [torch.float32, torch.float16]:\n",
    "    torch.set_default_dtype(dt)\n",
    "    print(f\"{dt} time: {doit(d)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "# Lecture 4 - AI and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "## 4.1 Core AI and ML concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU activation function\n",
    "\n",
    "x = torch.linspace(-10, 10, 200)\n",
    "y = torch.relu(x)\n",
    "\n",
    "plt.plot(x.numpy(), y.numpy(), label='ReLU', color='blue')\n",
    "plt.title('ReLU Activation Function')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(\"../assets/images/relu_function.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "### Learning a linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning linear weights\n",
    "\n",
    "# Create structured data\n",
    "X = torch.zeros(100, 10, dtype=torch.float32)\n",
    "for i in range(100):\n",
    "    for j in range(10):\n",
    "        X[i, j] = (i + 1) + (j / 10)\n",
    "\n",
    "# Normalise to prevent exploding gradients\n",
    "X = (X - X.min()) / (X.max() - X.min())\n",
    "\n",
    "# Linear: y = 1, ..., 100\n",
    "y = torch.arange(1, 101, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "plt.plot(X[:,0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "dataset = TensorDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = nn.Linear(10, 1)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "num_epochs = 100\n",
    "loss_history = []\n",
    "prediction_history = {}\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for X_batch, y_batch in loader:\n",
    "        opt.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    loss_history.append(epoch_loss)\n",
    "\n",
    "    if epoch%10 == 0 or epoch == (num_epochs-1):\n",
    "        with torch.no_grad():\n",
    "            prediction_history[epoch] = model(X).detach().squeeze().numpy()\n",
    "        print(f\"Epoch {epoch+1}: Loss = {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../assets/images/training_loss_learning_linear_weights.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y = y.squeeze().numpy()\n",
    "plt.plot(X[:,0], true_y, label=\"True y\", color=\"black\", linewidth=2)\n",
    "for epoch, pred in prediction_history.items():\n",
    "    plt.plot(X[:,0], pred, label=f\"Epoch {epoch}\")\n",
    "plt.title(\"Evolution of Learned Function\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Predicted y\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../assets/images/model_predictions_over_training.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "    for i in range(5):\n",
    "        pred = y_pred[i].item()\n",
    "        true = y[i].item()\n",
    "        print(f\"y_pred = {pred:.2f}, y_true = {true:.2f}\")\n",
    "\n",
    "print(\"Weights:\", *model.weight.data.numpy()[0])\n",
    "print(\"Bias:\", model.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "### Learning a non-linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create structured data\n",
    "n = 20\n",
    "X = torch.zeros(100, n, dtype=torch.float32)\n",
    "for i in range(100):\n",
    "    for j in range(n):\n",
    "        X[i, j] = (i + 1) + (j / 10)\n",
    "\n",
    "# Normalise to prevent exploding gradients\n",
    "X = (X - X.min()) / (X.max() - X.min())\n",
    "\n",
    "# Non-linear: y = sqrt(100x + 1) * sin(2πx)\n",
    "y = torch.arange(1, 101, dtype=torch.float32)\n",
    "y = torch.sqrt(y)\n",
    "y = y*torch.sin(2*torch.pi*torch.arange(100, dtype=torch.float32)/100)\n",
    "y = y.reshape(-1,1)\n",
    "plt.plot(X[:,0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define non-linear model\n",
    "m = 1\n",
    "mm = 128\n",
    "if m == 2:\n",
    "    # Non-linear model\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(n, mm),\n",
    "        nn.SiLU(),\n",
    "        nn.Linear(mm, 1)\n",
    "    )\n",
    "else:\n",
    "    # Linear\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(n, 1),\n",
    "    )\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "loss_history = []\n",
    "prediction_history = {}\n",
    "\n",
    "# Training\n",
    "num_epochs = 300\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    for X_batch, y_batch in loader:\n",
    "        opt.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    loss_history.append(epoch_loss)\n",
    "\n",
    "    if epoch % 30 == 0 or epoch == (num_epochs-1):\n",
    "        with torch.no_grad():\n",
    "            prediction_history[epoch] = model(X).detach().squeeze().numpy()\n",
    "        print(f\"Epoch {epoch+1} loss: {epoch_loss:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Training Loss over Epochs (Non-linear Function)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"../assets/images/training_loss_learning_nonlinear_weights.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "true_y = y.squeeze().numpy()\n",
    "plt.plot(X[:,0], true_y, label=\"True target\", color=\"black\", linewidth=2)\n",
    "\n",
    "for epoch, pred in prediction_history.items():\n",
    "    plt.plot(X[:,0], pred, label=f\"Epoch {epoch}\")\n",
    "\n",
    "plt.title(\"Model Predictions Over Training (Nonlinear Model)\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Predicted y\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"../assets/images/model_predictions_over_training_nonlinear.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "## 4.2 Torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2., 3.], requires_grad=True)\n",
    "y = x[0]**2 + x[1]**2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# nn.Module is the base class for models and layers\n",
    "# Holds parameters (weights and biases)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Layer 1: 1 -> 16\n",
    "        self.fc1 = nn.Linear(1,16)\n",
    "        \n",
    "        # Non-linear activation function (ReLU in this case)\n",
    "        self.relu = nn.reLU()\n",
    "        \n",
    "        # Layer 2: 16 -> 1\n",
    "        self.fc2 = nn.Linear(16,1)\n",
    "\n",
    "    # Calling `model(x)` runs the model's `forward()` method\n",
    "    # Forward pass computes predictions from inputs (x)\n",
    "    # Builds the autograd graph (if grads enables on x)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "Learning a sine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input values x\n",
    "x = np.linspace(0, 2*np.pi, 1000)\n",
    "\n",
    "# Compute labels y = sin(x)\n",
    "y = np.sin(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset construction\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "x_t = torch.tensor(x).float().unsqueeze(1)\n",
    "y_t = torch.tensor(y).float().unsqueeze(1)\n",
    "\n",
    "data = TensorDataset(x_t, y_t)\n",
    "loader = DataLoader(data,\n",
    "                    batch_size=32,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and training loop\n",
    "\n",
    "# Learn non-linear mapping x -> \\hat{y}\n",
    "# Input: scalar x\n",
    "# Output: scalar \\hat{y}\n",
    "\n",
    "# Model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1,16), nn.ReLU(),\n",
    "    nn.Linear(16,16), nn.ReLU(),\n",
    "    nn.Linear(16,1)\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Optimiser\n",
    "opt = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr = 0.01\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "#     - Compare \\hat{y} and y\n",
    "#     - Minimise prediction error\n",
    "#     - Update model parameters\n",
    "for x_b, y_b in loader:\n",
    "    \n",
    "    # Zero the gradients from the previous iteration\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # Forward pass of the model to get predictions\n",
    "    y_p = model(x_b)\n",
    "\n",
    "    # Update loss given predictions y_p\n",
    "    loss = loss_fn(y_p, y_b)\n",
    "\n",
    "    # Backpropagation - compute gradients of loss wrt parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Optimiser - update parameters (weights and biases) in-place\n",
    "    # given the gradients\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "## 4.3 PyTorch fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define nonlinear function\n",
    "def f(x):\n",
    "    return x**4 - 3*x**3 + 2 - 0.2*x\n",
    "\n",
    "xx = np.linspace(-1, 3, 400)\n",
    "yy = f(xx)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(xx, yy, label=\"f(x)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"Gradient Descent on a Scalar Nonlinear Function\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial value\n",
    "x = torch.tensor([-0.5], requires_grad=True)\n",
    "\n",
    "# Optimiser\n",
    "opt = optim.SGD([x], lr=0.01)\n",
    "\n",
    "# Trajectory\n",
    "x_history = []\n",
    "y_history = []\n",
    "\n",
    "n_steps = 250\n",
    "\n",
    "for step in range(n_steps):\n",
    "    opt.zero_grad()\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    opt.step()\n",
    "\n",
    "    x_history.append(x.item())\n",
    "    y_history.append(y.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(xx, yy, label=\"f(x)\")\n",
    "plt.scatter(x_history, y_history, \n",
    "            c=range(len(x_history)), \n",
    "            cmap=\"viridis\", \n",
    "            s=30,\n",
    "            label=\"Optimisation path\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"Gradient Descent on a Scalar Nonlinear Function\")\n",
    "plt.legend()\n",
    "plt.colorbar(label=\"Iteration\")\n",
    "plt.grid()\n",
    "plt.savefig(\"../assets/images/minimisation_visualisation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "## 4.5 Gradient field and decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples\n",
    "N = 900\n",
    "\n",
    "X = torch.rand(N, 2) * 4 - 2\n",
    "\n",
    "# Parameters for ellipses\n",
    "a1, b1 = 1.0, 0.5\n",
    "a2, b2 = 0.6, 0.9\n",
    "theta1 = np.radians(30)\n",
    "theta2 = np.radians(-45)\n",
    "centre1 = torch.tensor([0.9, 0.9])\n",
    "centre2 = torch.tensor([-1.1, -0.2])\n",
    "\n",
    "X_shifted1 = X - centre1\n",
    "X_shifted2 = X - centre2\n",
    "\n",
    "x1_rot = \\\n",
    "    X_shifted1[:,0] * np.cos(theta1) + \\\n",
    "    X_shifted1[:,1] * np.sin(theta1)\n",
    "y1_rot = \\\n",
    "    -X_shifted1[:, 0] * np.sin(theta1) + \\\n",
    "    X_shifted1[:, 1] * np.cos(theta1)\n",
    "inside_ellipse1 = \\\n",
    "    ((x1_rot / a1) ** 2 + \\\n",
    "     (y1_rot / b1) ** 2) < 1\n",
    "\n",
    "x2_rot = \\\n",
    "    X_shifted2[:,0] * np.sin(theta2) + \\\n",
    "    X_shifted2[:,1] * np.cos(theta2)\n",
    "y2_rot = \\\n",
    "    -X_shifted2[:, 0] * np.sin(theta2) + \\\n",
    "    X_shifted2[:, 1] * np.cos(theta2)\n",
    "inside_ellipse2 = \\\n",
    "    ((x2_rot / a2) ** 2 + (y2_rot / b2) ** 2) < 1\n",
    "\n",
    "labels = (inside_ellipse1 | inside_ellipse2).float().unsqueeze(1).numpy()\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels.squeeze(), cmap=\"bwr\", alpha=1, edgecolors=\"white\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"Labels Defined by Two Ellipses\")\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-2, 2)\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "plt.savefig(\"../assets/images/decision_boundary_labels.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple classifier\n",
    "\n",
    "class BetterClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = BetterClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    opt.zero_grad()\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y_pred, torch.tensor(labels, dtype=torch.float32))\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display classification and gradients\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "xx, yy = torch.meshgrid(torch.linspace(x_min, x_max, 50),\n",
    "                        torch.linspace(y_min, y_max, 50),\n",
    "                        indexing='ij')\n",
    "\n",
    "print(xx.shape)\n",
    "print(xx.flatten().shape)\n",
    "\n",
    "grid_points = torch.stack([xx.flatten(), yy.flatten()], dim=1)\n",
    "print(grid_points.shape)\n",
    "\n",
    "grid_points.requires_grad = True\n",
    "\n",
    "grid_preds = model(grid_points)\n",
    "print(grid_preds.shape)\n",
    "\n",
    "grid_preds.backward(torch.ones_like(grid_preds))\n",
    "\n",
    "grid_preds_np = grid_preds.detach().numpy().reshape(xx.shape)\n",
    "print(grid_preds_np.shape)\n",
    "\n",
    "# Gradients\n",
    "grid_grads = grid_points.grad.detach().numpy()\n",
    "grad_magnitudes = np.linalg.norm(grid_grads, axis=1, keepdims=True)\n",
    "grad_magnitudes = np.clip(grad_magnitudes, 1, 1000)\n",
    "grid_grads /= grad_magnitudes\n",
    "grid_grads_x = grid_grads[:, 0].reshape(xx.shape)\n",
    "grid_grads_y = grid_grads[:, 1].reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.contourf(xx, yy, grid_preds_np, alpha=1, cmap=\"bwr\")\n",
    "plt.quiver(xx, yy, grid_grads_x, grid_grads_y, color=\"black\", scale=50)\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"Normalized Gradient Field and Decision Boundary\")\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-2, 2)\n",
    "plt.grid()\n",
    "plt.savefig(\"../assets/images/points_classified_with_gradients.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "# Lecture 5 - Neural Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "## 5.1 Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size, hidden_size1, hidden_size2, output_size = 1, 8, 6, 1\n",
    "model = FeedForwardNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function y = y(x)\n",
    "x = np.linspace(-2, 2, 500)\n",
    "y = 1 / (1 + np.exp(-5 * x))\n",
    "\n",
    "# Convert to tensor\n",
    "x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(1)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# --- Define model ----\n",
    "\n",
    "# Architecture\n",
    "class DeepFFNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1, self.fc2, self.fc3 = nn.Linear(1, 8), nn.Linear(8, 6), nn.Linear(6, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc3(\n",
    "            torch.relu(\n",
    "                self.fc2(\n",
    "                    torch.relu(\n",
    "                        self.fc1(x)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "model = DeepFFNN().to(torch.float32)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimiser\n",
    "optimiser = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(2000):\n",
    "    optimiser.zero_grad()\n",
    "    y_pred = model(x_tensor)\n",
    "    loss = criterion(y_pred, y_tensor)\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    loss_history.append(loss.item())\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f\"Epoch {epoch+1:4d}, Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_np = model(x_tensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "axes[0].plot(x, y, label=\"True\", linewidth=2)\n",
    "axes[0].plot(x, y_pred_np, \"r--\", label=\"NN Approx.\", linewidth=2)\n",
    "axes[0].set(title=\"Function Approximation\", xlabel=\"x\", ylabel=\"f(x)\"); axes[0].legend(); axes[0].grid()\n",
    "axes[1].semilogy(loss_history, \"r\", label=\"Loss\")\n",
    "axes[1].set(title=\"Loss Curve\", xlabel=\"Epochs\", ylabel=\"MSE\"); axes[1].legend(); axes[1].grid()\n",
    "plt.savefig(\"../assets/images/deep_nn_results.png\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "### Depth vs size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "x = np.linspace(-4, 4, 100)\n",
    "y = np.sin(np.sin(np.sin(x)))\n",
    "\n",
    "x_t = torch.tensor(x, dtype=torch.float32).unsqueeze(1)\n",
    "y_t = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "N0 = 64\n",
    "N1 = 7\n",
    "\n",
    "class Shallow(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, N0),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(N0, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, N1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(N1, N1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(N1, N1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(N1, N1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(N1, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# --- Parameter counting function -----------------------------\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=2000):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    losses = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        opt.zero_grad()\n",
    "        y_pred = model(x_t)\n",
    "        loss = loss_fn(y_pred, y_t)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [Shallow(), Deep()]\n",
    "\n",
    "params = [count_params(m) for m in models]\n",
    "print(params)\n",
    "\n",
    "# Training\n",
    "losses = [train(m) for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yf = [m(x_t).numpy() for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference result\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x, y, label=\"true\", lw=2)\n",
    "plt.plot(x, yf[0], \"--\", label=\"shallow\")\n",
    "plt.title(\"Shallow network\")\n",
    "plt.legend(); plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(x, y, label=\"true\", lw=2)\n",
    "plt.plot(x, yf[1], \"--\", label=\"deep\")\n",
    "plt.title(\"Deep network\")\n",
    "plt.legend(); plt.grid()\n",
    "\n",
    "plt.savefig(\"../assets/images/shallow_vs_deep.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loss\n",
    "\n",
    "plt.semilogy(losses[0], label=\"shallow\")\n",
    "plt.semilogy(losses[1], label=\"deep\")\n",
    "plt.legend(); plt.grid()\n",
    "plt.title(\"Training loss\")\n",
    "plt.savefig(\"../assets/images/shallow_vs_deep_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_true = np.gradient(y, x)\n",
    "dy_s = np.gradient(yf[0].squeeze(), x)\n",
    "dy_d = np.gradient(yf[1].squeeze(), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, dy_true, label=\"true\", linewidth=2)\n",
    "plt.plot(x, dy_s, \"--\", label=\"shallow\")\n",
    "plt.plot(x, dy_d, \"--\", label=\"deep\")\n",
    "plt.title(\"Derivatives\")\n",
    "plt.legend(); plt.grid()\n",
    "plt.savefig(\"../assets/images/shallow_vs_deep_gradients.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "## 5.2 Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch-geometric\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN with two hidden layers\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_feats_y):\n",
    "        super().__init__()\n",
    "\n",
    "        # Graph Convolutional Layers (Message Passing)\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels[0])\n",
    "        self.conv2 = GCNConv(hidden_channels[0], hidden_channels[1])\n",
    "\n",
    "        # Fully Connected Layers (MLP Head)\n",
    "        self.fc1 = nn.Linear(hidden_channels[1], hidden_channels[0])\n",
    "        self.fc2 = nn.Linear(hidden_channels[0], num_feats_y)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        # Message Passing with GCN Layers\n",
    "        x = F.leaky_relu(self.conv1(x, edge_index))\n",
    "        x = F.leaky_relu(self.conv2(x, edge_index))\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 25\n",
    "xa = 10\n",
    "x_grid = torch.linspace(0, xa, nx)\n",
    "x_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph configuration - p1 and p2 are the parametric coordinates of points on the unit circle\n",
    "p1 = torch.sin(2 * torch.pi * x_grid / xa)\n",
    "p2 = torch.cos(2 * torch.pi * x_grid / xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_grid, p1)\n",
    "plt.plot(x_grid, p2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(p1, p2)\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjacency matrix (chord distance between every pair)\n",
    "diff = torch.sqrt((p1.repeat(nx, 1).T - p1)**2 + (p2.repeat(nx, 1).T - p2)**2)\n",
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge index\n",
    "threshold = 0.5\n",
    "edge_index = (diff < threshold).float().nonzero(as_tuple=False).t().contiguous()\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the connectivity\n",
    "\n",
    "x = p2.numpy()  # cos(θ) - x coordinates\n",
    "y = p1.numpy()  # sin(θ) - y coordinates\n",
    "\n",
    "# Plot edges\n",
    "edge_index_np = edge_index.numpy()\n",
    "for i, j in edge_index_np. T:\n",
    "    plt.plot([x[i], x[j]], [y[i], y[j]], 'b-', alpha=0.3, linewidth=0.5)\n",
    "\n",
    "# Plot nodes\n",
    "plt.scatter(x, y, c='red', s=50, zorder=5)\n",
    "\n",
    "plt.scatter(x[0], y[0], c='blue', s=50, zorder=5)\n",
    "plt.scatter(x[1], y[1], c='green', s=50, zorder=5)\n",
    "\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.title(f'Graph connectivity (threshold = {threshold})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node features (x) and node labels (y)\n",
    "\n",
    "# x is a matrix, each row is the coordinates of one point\n",
    "# y are random binary labels (0 or 1), the target for classification\n",
    "\n",
    "data = Data(\n",
    "    x = torch.cat((p1.unsqueeze(1), p2.unsqueeze(1)), dim=1),\n",
    "    y = torch.randint(0, 2, (nx, 1)).float(),\n",
    "    edge_index = edge_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "model = GNNModel(num_features=2, hidden_channels=[8, 16], num_feats_y=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count edges\n",
    "num_edges = edge_index.shape[1]\n",
    "\n",
    "# Degree of each node\n",
    "degree_per_node = torch.bincount(edge_index[0])\n",
    "\n",
    "print(\"Num edges               = \", num_edges)\n",
    "print(\"Average degree per node = \", round(degree_per_node.float().mean().item(), 2))\n",
    "print(\"Max degree per node     = \", degree_per_node.max().item())\n",
    "\n",
    "# Print degree of first few nodes\n",
    "for i in range(min(10, nx)):  # Print up to 10 nodes\n",
    "    print(f\"Node {i} has {degree_per_node[i].item()} neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchviz\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass to generate graph visualisation\n",
    "y_pred = model(data.x, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = make_dot(y_pred,\n",
    "               params={**dict(model.named_parameters()), 'Input features': data.x},\n",
    "               show_attrs = True,\n",
    "               show_saved = True\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot.render(\"../assets/images/gnn_graph\", format=\"png\", cleanup = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of nodes\n",
    "nx_nodes = 12\n",
    "\n",
    "# Ellipse parameters\n",
    "a, b = 10, 4\n",
    "\n",
    "# Adjacency matrix for 4-neighbour connectivity (2 left, 2 right)\n",
    "adjm = torch.zeros((nx_nodes, nx_nodes), dtype = torch.float)\n",
    "\n",
    "# Populate\n",
    "for i in range(nx_nodes):\n",
    "    adjm[i, (i-1)%nx_nodes] = 1 # Left neighbour\n",
    "    adjm[i, (i+1)%nx_nodes] = 1 # Right neighbour\n",
    "    adjm[i, (i-2)%nx_nodes] = 1 # Second left neighbour\n",
    "    adjm[i, (i+2)%nx_nodes] = 1 # Second right neighbour\n",
    "\n",
    "print(adjm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = adjm.nonzero(as_tuple=False).t().contiguous()\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viz\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add edges\n",
    "edges = edge_index.t().tolist()\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Generate node positions\n",
    "tau_values = np.linspace(0, 2*np.pi, nx_nodes, endpoint=False)\n",
    "x_positions = a * np.sin(tau_values)\n",
    "y_positions = b * np.cos(tau_values)\n",
    "\n",
    "plt.plot(x_positions, y_positions)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = {i: (x_positions[i], y_positions[i]) for i in range(nx_nodes)}\n",
    "\n",
    "node_colors = plt.cm.rainbow(np.linspace(0, 1, nx_nodes))\n",
    "\n",
    "plt.figure(figsize=(a, b))\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=300, alpha=0.9)\n",
    "\n",
    "curved_edges = [(u, v) for u, v in G.edges() if abs(u - v) > 1 and not (u == 0 and v == nx_nodes - 1)]  # Curved edges for longer jumps\n",
    "straight_edges = [(u, v) for u, v in G.edges() if abs(u - v) == 1 or (u == 0 and v == nx_nodes - 1)]  # Direct neighbors + periodic edges\n",
    "\n",
    "# Draw straight and curved edges separately\n",
    "nx.draw_networkx_edges(G, pos, edgelist=straight_edges, edge_color=\"gray\", width=1.5, alpha=0.7)\n",
    "nx.draw_networkx_edges(G, pos, edgelist=curved_edges, edge_color=\"gray\", width=1.5, alpha=0.7, style=\"dashed\")\n",
    "\n",
    "# Annotate nodes\n",
    "labels = {i: f\"N{i}\" for i in range(nx_nodes)}\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=9, font_weight=\"bold\")\n",
    "\n",
    "# Add edge labels (showing node connections)\n",
    "edge_labels = {(u, v): f\"{u}-{v}\" for u, v in edges}\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=7, font_color=\"black\")\n",
    "\n",
    "plt.title(f\"Graph Structure for GNN\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"../assets/images/gnn_graph_connectivity.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.data as geom_data\n",
    "import torch_geometric.nn as geom_nn\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define parameters\n",
    "xa, nx, nt, v = 10, 25, 15, 0.6\n",
    "\n",
    "# Create grid and function data\n",
    "x_grid = np.linspace(0, xa, nx + 1)[:-1]\n",
    "z = np.zeros([nt, nx])\n",
    "for j in range(nt):\n",
    "    z[j, :] = np.sin((2 * np.pi / xa) * x_grid - v * j)\n",
    "\n",
    "# Create adjacency matrix\n",
    "p1 = np.sin(2 * np.pi * x_grid / xa)\n",
    "p2 = np.cos(2 * np.pi * x_grid / xa)\n",
    "p1m, p2m = np.tile(p1, (nx, 1)).T, np.tile(p2, (nx, 1)).T\n",
    "diff = np.sqrt((p1m - p1m.T) ** 2 + (p2m - p2m.T) ** 2)\n",
    "adjm = (diff < 0.5).astype(int)\n",
    "edge_index = torch.tensor(np.array(np.nonzero(adjm)), dtype=torch.long)\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, Y_train = z[:-1], z[1:]\n",
    "X_test, Y_test = z[:-1], z[1:]\n",
    "\n",
    "# Create feature tensors and data loader\n",
    "features_tmp2 = torch.tensor(np.arange(1, nx + 1) / nx, dtype=torch.float).unsqueeze(1)\n",
    "train_list, test_list = [], []\n",
    "for k in range(X_train.shape[0]):\n",
    "    features_k_tmp1 = torch.tensor(X_train[k, :], dtype=torch.float).unsqueeze(1)\n",
    "    features_k = torch.cat((features_k_tmp1, features_tmp2), dim=1)\n",
    "    labels_k = torch.tensor(Y_train[k, :], dtype=torch.float).unsqueeze(1)\n",
    "    data = geom_data.Data(x=features_k, y=labels_k, edge_index=edge_index)\n",
    "    train_list.append(data)\n",
    "\n",
    "for k in range(X_test.shape[0]):\n",
    "    features_k_tmp1 = torch.tensor(X_test[k, :], dtype=torch.float).unsqueeze(1)\n",
    "    features_k = torch.cat((features_k_tmp1, features_tmp2), dim=1)\n",
    "    labels_k = torch.tensor(Y_test[k, :], dtype=torch.float).unsqueeze(1)\n",
    "    data = geom_data.Data(x=features_k, y=labels_k, edge_index=edge_index)\n",
    "    test_list.append(data)\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader  # neuer Import\n",
    "\n",
    "train_loader = DataLoader(train_list, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_list, batch_size=1, shuffle=False)\n",
    "\n",
    "# Define the GNN model\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_feats_y):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = geom_nn.GCNConv(num_features, hidden_channels[0])\n",
    "        self.conv2 = geom_nn.GCNConv(hidden_channels[0], hidden_channels[1])\n",
    "        self.conv3 = geom_nn.GCNConv(hidden_channels[1], hidden_channels[2])\n",
    "        self.conv4 = geom_nn.GCNConv(hidden_channels[2], hidden_channels[3])\n",
    "        self.fc1 = nn.Linear(hidden_channels[3], hidden_channels[2])\n",
    "        self.fc2 = nn.Linear(hidden_channels[2], hidden_channels[0])\n",
    "        self.fc3 = nn.Linear(hidden_channels[0], num_feats_y)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.leaky_relu(self.conv1(x, edge_index))\n",
    "        x = F.leaky_relu(self.conv2(x, edge_index))\n",
    "        x = F.leaky_relu(self.conv3(x, edge_index))\n",
    "        x = F.leaky_relu(self.conv4(x, edge_index))\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Initialize model, optimizer, and criterion\n",
    "model = GNNModel(num_features=2, hidden_channels=[4 * nt, 4 * nt, 4 * nt, 4 * nt], num_feats_y=1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 1500\n",
    "train_mse, test_mse = [], []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    train_mse_tmp = []\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch.x, batch.edge_index)\n",
    "        loss = criterion(output, batch.y)\n",
    "        train_mse_tmp.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_mse.append(np.mean(train_mse_tmp))\n",
    "\n",
    "    model.eval()\n",
    "    test_mse_tmp = []\n",
    "    for batch in test_loader:\n",
    "        y_pred = model(batch.x, batch.edge_index)\n",
    "        test_loss = criterion(y_pred, batch.y)\n",
    "        test_mse_tmp.append(test_loss.item())\n",
    "    test_mse.append(np.mean(test_mse_tmp))\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch + 1}, Train Loss: {train_mse[epoch]}, Test Loss: {test_mse[epoch]}')\n",
    "\n",
    "# Plot training and test MSE\n",
    "plt.plot(np.arange(epochs), train_mse, '*', label='Train Loss')\n",
    "plt.plot(np.arange(epochs), test_mse, '*', label='Test Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training and Test Loss\")\n",
    "plt.savefig(\"../assets/images/gnn_loss_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse_tmp = []\n",
    "\n",
    "# Counter for images\n",
    "ni = 1\n",
    "\n",
    "# Select a few test cases\n",
    "test_cases = np.random.choice(range(len(X_train) - 1), size=2, replace=False)\n",
    "\n",
    "for idx in test_cases:\n",
    "\n",
    "    # Get a batch from the selected test case\n",
    "    original_func = X_train[idx]\n",
    "    translated_func = X_train[idx + 1]\n",
    "    input_features = train_list[idx].x\n",
    "\n",
    "    # Predict with the model\n",
    "    with torch.no_grad():\n",
    "        predicted_func = model(input_features, train_list[idx].edge_index).numpy().flatten()\n",
    "\n",
    "    # Compute MSE for this test case\n",
    "    mse = np.mean((translated_func - predicted_func) **2)\n",
    "    test_mse_tmp.append(mse)\n",
    "\n",
    "    # Plot comparison for this test case (Original, Translated, and Predicted)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(original_func, label=\"Original Function\", linestyle='-', marker='o', color='blue')\n",
    "    plt.plot(translated_func, label=\"Translated Function\", linestyle='-', marker='x', color='green')\n",
    "    plt.plot(predicted_func, label=\"Predicted Translated Function\", linestyle='--', marker='s', color='red')\n",
    "    plt.title(f\"Function {idx} - MSE: {mse:.4f}\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('Node index')\n",
    "    plt.ylabel('Function value')\n",
    "    plt.savefig(f\"../assets/images/gnn_test_{ni}.png\")\n",
    "    ni+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144",
   "metadata": {},
   "source": [
    "## 5.3 CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_function_data(num_samples=5000, num_points=50, err=0.02):\n",
    "    X = []\n",
    "    y = []\n",
    "    functions = ['sine-cosine', 'gaussian', 'polynomial']\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        x = np.linspace(-1, 1, num_points)\n",
    "        func_type = np.random.choice(functions)\n",
    "\n",
    "        # Initialize a default y_values to prevent UnboundLocalError\n",
    "        y_values = np.zeros(num_points)\n",
    "        label = -1\n",
    "\n",
    "        if func_type == 'sine-cosine':\n",
    "            freq = np.random.uniform(1, 5)  \n",
    "            phase = np.random.uniform(0, 2 * np.pi)\n",
    "            amp = np.random.uniform(0.5, 2)\n",
    "            y_values = amp * np.sin(freq * np.pi * x + phase) + err * np.random.randn(num_points)\n",
    "            label = 0\n",
    "\n",
    "        elif func_type == 'gaussian':\n",
    "            mu = np.random.uniform(-0.5, 0.5)  \n",
    "            sigma = np.random.uniform(0.2, 0.5)  \n",
    "            amp = np.random.uniform(0.5, 2)\n",
    "            y_values = amp * np.exp(-((x - mu) ** 2) / (2 * sigma ** 2)) + err * np.random.randn(num_points)\n",
    "            label = 1\n",
    "\n",
    "        elif func_type == 'polynomial':\n",
    "            a = np.random.uniform(-2, 2)\n",
    "            b = np.random.uniform(-2, 2)\n",
    "            c = np.random.uniform(-3, 3)\n",
    "            d = np.random.uniform(-0.5, 0.5)\n",
    "            y_values = a * x**3 + b * x**2 + c * x + d + err * np.random.randn(num_points)\n",
    "            label = 2\n",
    "\n",
    "        X.append(y_values)\n",
    "        y.append(label)\n",
    "\n",
    "    X = np.array(X).reshape(-1, 1, num_points)  # Add channel dimension\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Generate a large training and test dataset with adjustable noise\n",
    "X_train, y_train = generate_function_data(num_samples=10000, err=0.05)  # Low noise in training\n",
    "X_test, y_test = generate_function_data(num_samples=2000, err=0.2)  # Higher noise in test set\n",
    "\n",
    "print(f\"Train Data Shape: {X_train.shape}, Train Labels Shape: {y_train.shape}\")\n",
    "print(f\"Test Data Shape: {X_test.shape}, Test Labels Shape: {y_test.shape}\")\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "for i, idx in enumerate(torch.randperm(len(X_train))[:6]):\n",
    "    plt.subplot(1, 6, i + 1)\n",
    "    plt.plot(X_train[idx][0].cpu().numpy())\n",
    "    plt.title(['sine-cosine', 'gaussian', 'polynomial'][y_train[idx].item()])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = 5\n",
    "\n",
    "class FunctionClassifierCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=1,  out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 50, 128)\n",
    "        self.fc2 = nn.Linear(128, num_categories)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise model\n",
    "model = FunctionClassifierCNN()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training ---\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "print(\"device\", device)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "# Convert dataset into DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    list(zip(X_train, y_train)),\n",
    "    batch_size=batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "# Loss as a function of epochs\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        opt.zero_grad()\n",
    "        loss = criterion(model(batch_X), batch_y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "    # Save epoch loss\n",
    "    loss_history.append(total_loss / len(train_loader))\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss_history[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,5))\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.savefig(\"../assets/images/cnn_training_loss.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    list(zip(X_test, y_test)),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "accuracy =  100 * correct/total\n",
    "print(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "import random\n",
    "\n",
    "num_examples = 12\n",
    "\n",
    "X_new, y_new = generate_function_data(num_samples=num_examples)\n",
    "X_new = X_new.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_new)\n",
    "    _, predicted_labels = torch.max(predictions, 1)\n",
    "\n",
    "func_names = ['Sine-Cosine', 'Gaussian', 'Polynomial']\n",
    "\n",
    "# Plot the results\n",
    "rows = num_examples // 4  # Show 4 per row\n",
    "plt.figure(figsize=(12, 3 * rows))\n",
    "\n",
    "for i in range(num_examples):\n",
    "    correct = predicted_labels[i] == y_new[i]  # Check if prediction is correct\n",
    "    color = 'blue' if correct else 'red'  # Blue for correct, red for incorrect\n",
    "\n",
    "    plt.subplot(rows, 4, i + 1)\n",
    "    plt.plot(np.linspace(-1, 1, 50), X_new[i].cpu().numpy().squeeze(), color=color, label=f\"Pred: {func_names[predicted_labels[i]]}\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"True: {func_names[y_new[i]]}\", color=color)  # Color title for extra clarity\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../assets/images/cnn_test_predictions.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152",
   "metadata": {},
   "source": [
    "## 5.4 LSTM Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate normal sine wave data with random phase shift\n",
    "def generate_sensor_data(num_samples=100, seq_length=50, anomaly_ratio=0.1):\n",
    "    x = []\n",
    "    labels = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        phase_shift = np.random.uniform(0, 2*np.pi)\n",
    "        time_series = np.sin(np.linspace(0, 2*np.pi, seq_length) + phase_shift) + 0.1 * np.random.rand(seq_length)\n",
    "        label = 0 # Normal\n",
    "\n",
    "        # Inject anomalies\n",
    "        if np.random.rand() < anomaly_ratio:\n",
    "            # Add large spikes\n",
    "            time_series += np.random.uniform(-2, 2, size=seq_length)\n",
    "            label = 1\n",
    "\n",
    "        x.append(time_series)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(x), np.array(labels)\n",
    "\n",
    "# Training/test data\n",
    "num_samples = 2000\n",
    "train_frac = 0.8\n",
    "bndry = math.floor(0.8*2000)\n",
    "X, y = generate_sensor_data(num_samples=num_samples)\n",
    "X_train, X_test = torch.tensor(X[:bndry], dtype=torch.float32), torch.tensor(X[bndry:], dtype=torch.float32)\n",
    "y_train, y_test = y[:bndry], y[bndry:]\n",
    "\n",
    "# Reshape for LSTM input\n",
    "X_train = X_train.unsqueeze(-1)\n",
    "X_test = X_test.unsqueeze(-1)\n",
    "\n",
    "print(f\"Train Data Shape: {X_train.shape}, Test Data Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_indices = np.where(y_train == 0)[0][:3]\n",
    "anomaly_indices = np.where(y_train == 1)[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot normal sequences\n",
    "for i, idx in enumerate(normal_indices):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.plot(X_train[idx].squeeze().cpu().numpy(), label=\"Normal\", color=\"blue\")\n",
    "    plt.title(\"Normal Sensor Data\")\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "# Plot anomalous sequences\n",
    "for i, idx in enumerate(anomaly_indices):\n",
    "    plt.subplot(2, 3, i + 4)\n",
    "    plt.plot(X_train[idx].squeeze().cpu().numpy(), label=\"Anomaly\", color=\"red\")\n",
    "    plt.title(\"Anomalous Sensor Data\")\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../assets/images/lstm_sensor_data_samples.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=32, num_layers=2, seq_length=50):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM layers\n",
    "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.decoder = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # Final layer to reconstruct output\n",
    "        self.output_layer = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Encode input\n",
    "        _, (hidden, cell) = self.encoder(x)\n",
    "\n",
    "        # Initialise decoder input as zeros\n",
    "        decoder_input = torch.zeros(batch_size, self.seq_length, 1).to(x.device)\n",
    "\n",
    "        # Decode using last hidden state from encoder\n",
    "        decoder_output, _ = self.decoder(decoder_input, (hidden, cell))\n",
    "\n",
    "        x_reconstructed = self.output_layer(decoder_output)\n",
    "\n",
    "        return x_reconstructed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise model with correct sequence length\n",
    "model = LSTMAutoencoder(seq_length=50).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr = 0.010)\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Track loss history\n",
    "loss_history = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        opt.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    loss_history.append(epoch_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history, label=\"Loss\")\n",
    "plt.xlabel(\"Epochs\"), plt.ylabel(\"Loss\"), plt.title(\"LSTM Training Loss\")\n",
    "plt.legend(), plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute reconstruction error on test data\n",
    "model.eval()\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "with torch.no_grad():\n",
    "    X_reconstructed = model(X_test)\n",
    "\n",
    "reconstruction_errors = torch.mean((X_test - X_reconstructed)**2, dim=(1, 2)).cpu().numpy()\n",
    "\n",
    "# Set anomaly threshold\n",
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test) * 100\n",
    "print(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "# Plot normal example\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(X_test[0].cpu().numpy(), label=\"Original\")\n",
    "plt.plot(X_reconstructed[0].cpu().numpy(), label=\"Reconstructed\", linestyle=\"dashed\")\n",
    "plt.title(\"Normal Sequence\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot anomaly example\n",
    "anomaly_idx = np.argmax(reconstruction_errors)  # Most anomalous sample\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(X_test[anomaly_idx].cpu().numpy(), label=\"Original\")\n",
    "plt.plot(X_reconstructed[anomaly_idx].cpu().numpy(), label=\"Reconstructed\", linestyle=\"dashed\", color=\"red\")\n",
    "plt.title(\"Anomalous Sequence\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../assets/images/lstm_anomaly_detection.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Select 12 random test samples\n",
    "num_samples = 12\n",
    "indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "\n",
    "# Compute reconstruction errors\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_reconstructed = model(X_test.to(device))\n",
    "\n",
    "reconstruction_errors = torch.mean((X_test - X_reconstructed) ** 2, dim=(1, 2)).cpu().numpy()\n",
    "\n",
    "# Detect anomalies based on threshold\n",
    "threshold = np.percentile(reconstruction_errors, 90)\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)  # 1 = Anomaly, 0 = Normal\n",
    "\n",
    "# Plot the selected samples\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, idx in enumerate(indices):\n",
    "    color = 'red' if y_pred[idx] == 1 else 'blue'\n",
    "    \n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    plt.plot(X_test[idx].cpu().numpy(), color=color, label=\"Original\")\n",
    "    plt.plot(X_reconstructed[idx].cpu().numpy(), linestyle=\"dashed\", color=\"black\", label=\"Reconstructed\")\n",
    "    plt.title(f\"{'Anomaly' if y_pred[idx] == 1 else 'Normal'}\", color=color)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.legend(fontsize=8, loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../assets/images/lstm_anomaly_detection_samples.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164",
   "metadata": {},
   "source": [
    "# Lecture 6 - LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display\n",
    "%pip install seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    0: \"\",              # padding token (ignored in loss)\n",
    "    1: \"I\", 2: \"am\", 3: \"you\", 4: \"is\", 5: \"we\", 6: \"are\",\n",
    "    7: \"a\", 8: \"an\", 9: \"the\",\n",
    "    10: \"simple\", 11: \"example\", 12: \"with\",\n",
    "    13: \"and\", 14: \"but\", 15: \"or\",\n",
    "    16: \"not\", 17: \"only\", 18: \"also\",\n",
    "    19: \"how\", 20: \"what\", 21: \"why\",\n",
    "    22: \"can\", 23: \"must\", 24: \"should\",\n",
    "    25: \"want\", 26: \"has\", 27: \"have\", 28: \"had\",\n",
    "    29: \"to\", 30: \"home\", 31: \"play\", 32: \"in\",\n",
    "    33: \"garden\", 34: \"weather\", 35: \"nice\",\n",
    "    36: \"drives\", 37: \"Berlin\", 38: \"reads\", 39: \"book\",\n",
    "    40: \"she\", 41: \"he\", 42: \"go\",\n",
    "    43: \"hungry\", 44: \"tired\", 45: \"happy\", 46: \"sad\",\n",
    "    47: \"it\", 48: \"good\", 49: \"this\", 50: \"bad\",\n",
    "    51: \"eat\", 52: \"drink\", 53: \"come\",\n",
    "    54: \"they\", 55: \"was\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I am hungry\",\n",
    "    \"you are tired\",\n",
    "    \"we are happy\",\n",
    "    \"they are sad\",\n",
    "    \"it is simple\",\n",
    "    \"the weather is nice\",\n",
    "    \"this is bad\",\n",
    "    \"this was good\",\n",
    "    \"we want to eat\",\n",
    "    \"they want to drink\",\n",
    "    \"you can come\",\n",
    "    \"we go home\",\n",
    "    \"they play in the garden\",\n",
    "    \"the weather is nice\",\n",
    "    \"he drives to Berlin\",\n",
    "    \"she reads a book\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(\" \".join(sentences).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170",
   "metadata": {},
   "outputs": [],
   "source": [
    "[_ for _ in vocab.values() if _ not in set(\" \".join(sentences).split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just the raw, untrained embeddings\n",
    "\n",
    "d_model = 32     # embedding dimension\n",
    "\n",
    "# Initialises a matrix of size (vocab_size, d_model) with random numbers\n",
    "embedding_layer = nn.Embedding(\n",
    "    num_embeddings=vocab_size,\n",
    "    embedding_dim=d_model\n",
    ")\n",
    "\n",
    "# Single input \"I am hungry\"\n",
    "input_tokens = torch.tensor([1, 2, 43])\n",
    "\n",
    "# Forward pass\n",
    "# Each integer token is replaced with a vector of length d_model\n",
    "with torch.no_grad():\n",
    "    output_vectors = embedding_layer(input_tokens)\n",
    "\n",
    "print(f\"Input shape:  {input_tokens.shape}\")\n",
    "print(f\"Output shape: {output_vectors.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.heatmap(output_vectors, annot=False, cmap=\"viridis\", cbar=True)\n",
    "plt.title(\"Visualizing Embeddings for: 'I', 'am', 'hungry'\")\n",
    "plt.ylabel(\"Token Position\")\n",
    "plt.xlabel(\"Embedding Dimension (0-31)\")\n",
    "plt.yticks([0.5, 1.5, 2.5], labels=[\"I (ID 1)\", \"am (ID 2)\", \"hungry (ID 43)\"], rotation=0)\n",
    "plt.savefig(\"../assets/images/embeddings_structure.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a pure embeddings model\n",
    "\n",
    "# Simplify the vocab\n",
    "vocab = {\n",
    "    0: \"\", 1: \"I\", 2: \"am\", 3: \"you\", 4: \"is\", 5: \"we\", 6: \"are\", 36: \"drives\",\n",
    "    37: \"Berlin\", 41: \"he\", 42: \"go\", 43: \"hungry\", 44: \"tired\", 45: \"happy\", 46: \"sad\",\n",
    "    54: \"they\", 30: \"home\"\n",
    "}\n",
    "# Inverse vocab for printing\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Train on subject+verb -> adjective\n",
    "# These pairs teach the model that hungry/tired/happy/sad fill the same \"slot\"\n",
    "training_data = [\n",
    "    ([\"we\", \"are\"], \"hungry\"),\n",
    "    ([\"we\", \"are\"], \"tired\"),\n",
    "    ([\"we\", \"are\"], \"happy\"),\n",
    "    ([\"we\", \"are\"], \"sad\"),\n",
    "    ([\"we\", \"go\"],  \"home\"),        # \"home\" is a location\n",
    "    ([\"we\", \"go\"],  \"Berlin\"),  # \"Berlin\" is a location (using \"he drives\" conceptually)\n",
    "]\n",
    "\n",
    "# Helper function\n",
    "def encode(words):\n",
    "    return torch.tensor(\n",
    "        [inv_vocab[w] for w in words], dtype=torch.long\n",
    "    )\n",
    "\n",
    "# Continuous bag of words model\n",
    "class SimpleCBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs shape: [batch_size, context_len]\n",
    "\n",
    "        # Get embeddins\n",
    "        embeds = self.embedding(inputs)\n",
    "\n",
    "        # Aggregate\n",
    "        # Average the vectors of the input words to create one vector for the fragment\n",
    "        combined_vector = torch.mean(embeds, dim=1)\n",
    "\n",
    "        # Predict the target word based on the combined vector\n",
    "        logits = self.linear(combined_vector)\n",
    "\n",
    "        return logits\n",
    "\n",
    "d_model = 2  # easy to visualise\n",
    "vocab_size = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "model = SimpleCBOW(vocab_size, d_model)\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=0.05)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(250):\n",
    "    total_loss = 0\n",
    "\n",
    "    for context, target in training_data:\n",
    "\n",
    "        x = encode(context).unsqueeze(0)\n",
    "        y = encode([target])\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch:3d} loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at learned vectors for specific words\n",
    "\n",
    "target_words = [\"hungry\", \"tired\", \"happy\", \"sad\", \"Berlin\", \"home\"]\n",
    "vectors = {}\n",
    "\n",
    "#\n",
    "output_weights = model.linear.weight.detach().numpy()\n",
    "\n",
    "\n",
    "for w in target_words:\n",
    "    token_id = inv_vocab[w]\n",
    "    vec = output_weights[token_id]\n",
    "    vectors[w] = vec\n",
    "\n",
    "def dist(w1, w2):\n",
    "    return np.linalg.norm(vectors[w1] - vectors[w2])\n",
    "\n",
    "print(f\"Distance happy <-> sad    = {dist('happy', 'sad'):.4f}\")\n",
    "print(f\"Distance happy <-> Berlin = {dist('happy', 'Berlin'):4f}\")\n",
    "print(f\"Distance home  <-> Berlin = {dist('home', 'Berlin'):4f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for w, vec in vectors.items():\n",
    "    plt.scatter(vec[0], vec[1], s=100)\n",
    "    plt.text(vec[0]+0.05, vec[1]+0.05, w, fontsize=12)\n",
    "\n",
    "plt.title(\"Learned Word Embeddings (2D Space)\")\n",
    "plt.grid(True)\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0, color='black', linewidth=0.5)\n",
    "#plt.savefig(\"../assets/images/learned_word_embeddings_2d.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=100):\n",
    "        super().__init__()\n",
    "\n",
    "        # Matrix of size [max_len, d_model]\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # Divisor term controls frequency of sine/cosine curves\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * \n",
    "            (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        # Apply sin to even indices, cos to odd\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # Add a 'batch' dimension\n",
    "        # REMOVED THE .transpose(0,1) FROM THE ORIGINAL WHICH WAS A BUG(?)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # Register as a buffer\n",
    "        # Saved with model, but not trainable\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionAwareCBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, max_len=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # New: positional encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "        # Final projection to the vocabulary\n",
    "        self.linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # Look up token embeddings\n",
    "        x = self.embedding(inputs)\n",
    "\n",
    "        # Add positional info\n",
    "        x = self.pos_encoder(x)\n",
    "\n",
    "        # Average - replaced with Self-Attention in the Transformer\n",
    "        combined_vector = x.view(x.size(0), -1)\n",
    "\n",
    "        logits = self.linear(combined_vector)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise model and test order-awareness\n",
    "\n",
    "# Setup\n",
    "vocab = {0: \"\", 1: \"we\", 2: \"are\", 3: \"happy\"}\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "d_model = 8\n",
    "vocab_size = 10\n",
    "\n",
    "def encode(words):\n",
    "    return torch.tensor(\n",
    "        [inv_vocab[w] for w in words], dtype=torch.long\n",
    "    ).unsqueeze(0)\n",
    "\n",
    "torch.manual_seed(42) # The \"God Mode\" switch that makes randomness predictable\n",
    "\n",
    "# Initialise model\n",
    "model = PositionAwareCBOW(vocab_size, d_model)\n",
    "\n",
    "# Experiment\n",
    "# CBOW: \"we are\" == \"are we\"\n",
    "\n",
    "input_1 = encode([\"we\", \"are\"])\n",
    "input_2 = encode([\"are\", \"we\"])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Manually step through forward() to get vectors\n",
    "    emb1 = model.embedding(input_1)\n",
    "    pos1 = model.pos_encoder(emb1)\n",
    "    vec1 = pos1.view(1, -1)\n",
    "    emb2 = model.embedding(input_2)\n",
    "    pos2 = model.pos_encoder(emb2)\n",
    "    vec2 = pos2.view(1, -1)\n",
    "\n",
    "diff = torch.norm(vec1 - vec2).item()\n",
    "\n",
    "print(f\"Vector: {vec1.numpy()[0][:4]}...\") # Print first 4 dims\n",
    "print(f\"Vector: {vec2.numpy()[0][:4]}...\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Euclidean Distance: {diff:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for visualisation\n",
    "# Generate the encodings\n",
    "d_model_viz = 128   # Large dimension to see the gradient\n",
    "max_len_viz = 100   # 100 positions (sequence length)\n",
    "pe_layer = PositionalEncoding(d_model_viz, max_len_viz)\n",
    "\n",
    "# Extract matrix (remove 'batch' dimension)\n",
    "# Shape [100, 128]\n",
    "pe_matrix = pe_layer.pe.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(pe_matrix, aspect='auto', cmap='RdBu', origin='lower')\n",
    "\n",
    "plt.title(\"Positional Encoding Matrix\")\n",
    "plt.xlabel(\"Embedding Dimension (Frequency)\")\n",
    "plt.ylabel(\"Position in Sequence (Time)\")\n",
    "plt.colorbar(label=\"Value (-1 to +1)\")\n",
    "plt.savefig(\"../assets/images/positional_encoding_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "positions = np.arange(0, 100)\n",
    "\n",
    "# Plot dimension 0 (High Frequency)\n",
    "plt.plot(positions, pe_matrix[:, 0], label=\"Dim 0 (High Freq)\", alpha=0.9)\n",
    "\n",
    "# Plot dimension 40 (Medium Frequency)\n",
    "plt.plot(positions, pe_matrix[:, 40], label=\"Dim 40 (Med Freq)\", alpha=0.9)\n",
    "\n",
    "# Plot dimension 80 (Low Frequency)\n",
    "plt.plot(positions, pe_matrix[:, 80], label=\"Dim 80 (Low Freq)\", alpha=0.9)\n",
    "\n",
    "plt.title(\"Sine/Cosine Waves at Different Dimensions\")\n",
    "plt.xlabel(\"Position in Sequence\")\n",
    "plt.ylabel(\"Encoding Value\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(\"../assets/images/positional_encoding_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Projections\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Compute Q, K, V\n",
    "        q = self.q_linear(x)\n",
    "        k = self.k_linear(x)\n",
    "        v = self.v_linear(x)\n",
    "        \n",
    "        # Scores (relevance)\n",
    "        scores = torch.matmul(\n",
    "            q, k.transpose(-2, -1)\n",
    "        ) / math.sqrt(self.d_model)\n",
    "\n",
    "        # Softmax\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = torch.matmul(weights, v)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len)\n",
    "        self.attention = SingleHeadAttention(d_model)\n",
    "        self.linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # Embed and position\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.pos_encoder(x)\n",
    "\n",
    "        # Self-attention\n",
    "        x = self.attention(x)\n",
    "\n",
    "        # Aggregate\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {0: \"\", 1: \"we\", 2: \"are\"}\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "d_model = 8\n",
    "vocab_size = 10\n",
    "max_len = 10\n",
    "\n",
    "def encode(words):\n",
    "    return torch.tensor(\n",
    "        [inv_vocab[w] for w in words], dtype=torch.long\n",
    "    ).unsqueeze(0)\n",
    "\n",
    "model = AttentionModel(vocab_size, d_model)\n",
    "\n",
    "input_1 = encode([\"we\", \"are\"])\n",
    "input_2 = encode([\"are\", \"we\"])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Forward pass\n",
    "    vec1 = model.embedding(input_1)\n",
    "    vec1 = model.pos_encoder(vec1)\n",
    "    vec1 = model.attention(vec1)\n",
    "    vec1_pooled = vec1.mean(dim=1)\n",
    "\n",
    "    vec2 = model.embedding(input_2)\n",
    "    vec2 = model.pos_encoder(vec2)\n",
    "    vec2 = model.attention(vec2)\n",
    "    vec2_pooled = vec2.mean(dim=1)\n",
    "\n",
    "diff = torch.norm(vec1_pooled - vec2_pooled).item()\n",
    "\n",
    "print(f\"Vector 'we are': {vec1_pooled.numpy()[0][:4]}...\")\n",
    "print(f\"Vector 'are we': {vec2_pooled.numpy()[0][:4]}...\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Euclidean Distance: {diff:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_model % num_heads == 0, \"d_model not divisible by num_heads\"\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        # Input: d_model\n",
    "        # Output: num_heads * d_k = d_model\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Shape: [batch, seq_len, d_model]\n",
    "        q = self.q_linear(x)\n",
    "        k = self.k_linear(x)\n",
    "        v = self.v_linear(x)\n",
    "\n",
    "        # Split into heads\n",
    "        # Reshape to: [batch, seq_len, num_heads, d_k]\n",
    "        # Then transpose to: [batch, num_heads, seq_len, d_k]\n",
    "        # This puts 'num_heads' into the batch dimension for parallel processing\n",
    "        q = q.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        k = k.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        v = v.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        # Mat-mult: [batch, heads, seq, d_k] x [batch, heads, d_k, seq]\n",
    "        # Result: [batch, heads, seq, seq]\n",
    "        scores = torch.matmul(\n",
    "            q, k.transpose(-2, -1)\n",
    "        ) / math.sqrt(self.d_k)\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # Apply weights to values\n",
    "        attention_output = torch.matmul(weights, v)\n",
    "\n",
    "        # Cat heads\n",
    "        # Transpose back: [batch, seq_len, num_heads, d_k]\n",
    "        # Flatten back: [batch, seq_len, d_model]\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # Final layer (mix heads)\n",
    "        return self.out_linear(attention_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "d_model = 16\n",
    "num_heads = 2\n",
    "seq_len = 3\n",
    "\n",
    "model = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "x = torch.randn(1, seq_len, d_model)\n",
    "\n",
    "# Forward Pass manually to catch the weights\n",
    "with torch.no_grad():\n",
    "    q = model.q_linear(x).view(1, -1, num_heads, d_model//num_heads).transpose(1, 2)\n",
    "    k = model.k_linear(x).view(1, -1, num_heads, d_model//num_heads).transpose(1, 2)\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_model//num_heads)\n",
    "    weights = F.softmax(scores, dim=1)\n",
    "\n",
    "    print(f\"Weights shape: {weights.shape}\")\n",
    "\n",
    "# Plotting\n",
    "labels = [\"Word A\", \"Word B\", \"Word C\"]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for h in range(num_heads):\n",
    "    # Extract heatmap for head 'h'\n",
    "    w_matrix = weights[0, h].numpy()\n",
    "    \n",
    "    sns.heatmap(w_matrix, annot=True, cmap=\"Blues\", ax=axes[h],\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    axes[h].set_title(f\"Head {h+1} Attention Pattern\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFN / MLP\n",
    "# Standard MLP applied to every token independently\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "# Transformer block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "\n",
    "        # Sub-layer 1 - attention\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Sub-layer 2 - feed-forward\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Sub-layer 1 - attention\n",
    "        attn_out = self.attention(x)\n",
    "\n",
    "        # Add and norm\n",
    "        x = self.norm1(x + attn_out)\n",
    "\n",
    "        # Calc FFN\n",
    "        ff_out = self.ff(x)\n",
    "\n",
    "        # Add and norm\n",
    "        x = self.norm2(x + ff_out)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 16\n",
    "num_heads = 2\n",
    "d_ff = 64\n",
    "seq_len = 5\n",
    "\n",
    "block = TransformerBlock(d_model, num_heads, d_ff)\n",
    "\n",
    "# Dummy input\n",
    "input_tensor = torch.randn(1, seq_len, d_model)\n",
    "\n",
    "# Fwd pass\n",
    "output_tensor = block(input_tensor)\n",
    "\n",
    "print(f\"Input Shape:  {input_tensor.shape}\")\n",
    "print(f\"Output Shape: {output_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = torch.norm(input_tensor - output_tensor).item()\n",
    "print(f\"Change Magnitude: {diff:.4f} (Vectors were updated)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check LayerNorm working\n",
    "# LayerNorm forces mean of last dimension to be ~0 and std to ~1.\n",
    "mean = output_tensor[0, 0].mean().item()\n",
    "std  = output_tensor[0, 0].std().item()\n",
    "print(f\"Output Token 0 Stats -> Mean: {mean:.4f}, Std: {std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Multi Head with causal mask\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Projections and split heads\n",
    "        q = self.q_linear(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        k = self.k_linear(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        v = self.v_linear(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Scores\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "\n",
    "        # New mask\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(weights, v)\n",
    "\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "\n",
    "        return self.out_linear(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, num_layers, max_len=100):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding and position\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "        # Stack of transformer blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(d_model, num_heads, d_ff=d_model*4)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Final output head\n",
    "        # Projects back from d_model to vocab_size\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x: [batch, seq_len]\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        # Creat causal mask\n",
    "        # Upper triangle is 0 (future), lower triangle is 1 (past)\n",
    "        mask = torch.tril(torch.ones(seq_len, seq_len)).to(x.device)\n",
    "\n",
    "        # Embed\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoder(x)\n",
    "\n",
    "        # Pass through blocks\n",
    "        for block in self.blocks:\n",
    "            # Update TransformerBlock to pass the mask to attention\n",
    "            # Assuming we updated TransformerBlock.forward to accept 'mask'\n",
    "            x = block(x, mask)\n",
    "\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_out = self.attention(x, mask)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        ff_out = self.ff(x)\n",
    "        x = self.norm2(x + ff_out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "vocab = {0: \"\", 1: \"we\", 2: \"are\", 3: \"happy\"}\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "d_model = 16\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "vocab_size = 4\n",
    "\n",
    "model = SimpleTransformer(vocab_size, d_model, num_heads, num_layers)\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Data\n",
    "# input [we, are]\n",
    "# output [are, happy]\n",
    "x = torch.tensor([1, 2]).unsqueeze(0)\n",
    "y = torch.tensor([2, 3]).unsqueeze(0)\n",
    "\n",
    "# Training\n",
    "for epoch in range(200):\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(x)  # [1, 2, vocab_size]\n",
    "\n",
    "    # Reshape for loss [batch*seq, vocab_size] vs. [batch*seq]\n",
    "    loss = criterion(logits.view(-1, vocab_size), y.view(-1))\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch} loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "model.eval()\n",
    "\n",
    "# Complete \"We ...\"\n",
    "test_input = torch.tensor([1]).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    logits = model(test_input)\n",
    "\n",
    "    pred_id = torch.argmax(logits[0, -1]).item()\n",
    "\n",
    "    print(f\"Prompt: 'we'\")\n",
    "    print(f\"Prediction ID: {pred_id} ({vocab[pred_id]})\")\n",
    "\n",
    "    test_input2 = torch.tensor([1, 2]).unsqueeze(0)\n",
    "    logits2 = model(test_input2)\n",
    "\n",
    "    pred_id2 = torch.argmax(logits2[0, -1]).item()\n",
    "\n",
    "    print(f\"Prompt: 'we are'\")\n",
    "    print(f\"Prediction ID: {pred_id2} ({vocab[pred_id2]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_words, max_tokens=5):\n",
    "    model.eval()\n",
    "\n",
    "    # Initial context\n",
    "    context_ids = [inv_vocab[w] for w in start_words.split()]\n",
    "    input_tensor = torch.tensor(context_ids).unsqueeze(0)\n",
    "\n",
    "    print(\"Starting with {start words}\")\n",
    "\n",
    "    # Generation loop\n",
    "    for _ in range(max_tokens):\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(input_tensor)\n",
    "\n",
    "        # Pick next token\n",
    "        next_token_logits = logits[0, -1, :]\n",
    "\n",
    "        # Greedy decoding\n",
    "        # (Temperature and random sampling here)\n",
    "        next_token_id = torch.argmax(next_token_logits).item()\n",
    "\n",
    "        # Decode\n",
    "        next_word = vocab[next_token_id]\n",
    "\n",
    "        if next_word == \"\": break\n",
    "\n",
    "        print(f\" -> Generated: '{next_word}'\")\n",
    "\n",
    "        # Append\n",
    "        next_tensor = torch.tensor([[next_token_id]])\n",
    "        input_tensor = torch.cat([input_tensor, next_tensor], dim=1)\n",
    "\n",
    "    final_sentence = \" \".join([vocab[idx.item()] for idx in input_tensor[0]])\n",
    "\n",
    "    print(f\"Final = {final_sentence}\")\n",
    "\n",
    "generate_text(model, \"we\", max_tokens=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196",
   "metadata": {},
   "source": [
    "# Lecture 7 - RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "198",
   "metadata": {},
   "source": [
    "# Lecture 8 - Multimodal LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "200",
   "metadata": {},
   "source": [
    "# Lecture 9 - Diffusion and Graph Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 1D distribution p(x)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Target distribution: mixture of Gaussians\n",
    "def sample_target(n):\n",
    "    comp = torch.randint(0, 3, (n,))\n",
    "    means = torch.tensor([-2.0, 0.5, 2.5])\n",
    "    stds  = torch.tensor([0.3, 0.2, 0.4])\n",
    "    x = torch.randn(n) * stds[comp] + means[comp]\n",
    "    return x.unsqueeze(1)\n",
    "\n",
    "# Draw reference samples\n",
    "x_ref = sample_target(20_000).numpy()\n",
    "\n",
    "plt.hist(x_ref, bins=200, density=True)\n",
    "plt.title(\"Target distribution p(x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NN - a straighforward FFNN / MLP\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "# (Used as a loss function in the standard way in the training loop;\n",
    "# but comparing the *distribution* of the predicted and true samples,\n",
    "# as opposed to pointwise comparison of paired x, \\hat{y}\n",
    "\n",
    "# NB \"sliced\" Wasserstein in 1D is just Wasserstein\n",
    "# Slicing relevant for higher dimensions where true Wasserstein expensive,\n",
    "# so project onto random 1D slices\n",
    "\n",
    "def sliced_wasserstein_1d(x_fake, x_real):\n",
    "    # Earth mover's distance in 1D is just: sort both distributions\n",
    "    # and compare element-wise\n",
    "    x_fake_sorted, _ = torch.sort(x_fake.view(-1))\n",
    "    x_real_sorted, _ = torch.sort(x_real.view(-1))\n",
    "    return torch.mean((x_fake_sorted - x_real_sorted) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "# Instantiate the network\n",
    "G = Generator()\n",
    "\n",
    "# Define optimiser\n",
    "optimizer = torch.optim.Adam(G.parameters(), lr=1e-3)\n",
    "\n",
    "n_samples = 4096\n",
    "for epoch in range(3001):\n",
    "\n",
    "    z = torch.randn(n_samples, 1)\n",
    "\n",
    "    # Generate fake / generated data for this epoch\n",
    "    x_fake = G(z)\n",
    "\n",
    "    # Real data drawn from the known true distribution, for this epoch\n",
    "    x_real = sample_target(n_samples)\n",
    "\n",
    "    loss = sliced_wasserstein_1d(x_fake, x_real)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 300 == 0:\n",
    "        print(f\"Epoch {epoch:4d} | loss = {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(50_000, 1)\n",
    "    x_gen = G(z).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(x_ref, bins=200, density=True, alpha=0.5, label=\"Target\")\n",
    "plt.hist(x_gen, bins=200, density=True, alpha=0.5, label=\"Generated\")\n",
    "plt.legend()\n",
    "plt.title(\"True distribution vs learned sampler\")\n",
    "plt.savefig(\"../assets/images/1d_distribution_sampling.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "209",
   "metadata": {},
   "source": [
    "# MLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/seppe-intelliprove/face-detection-onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fdlite import FaceDetection, FaceDetectionModel\n",
    "from fdlite.render import Colors, detections_to_render_data, render_to_image\n",
    "import PIL\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(image: PIL.Image):\n",
    "    detect_faces = FaceDetection(model_type=FaceDetectionModel.BACK_CAMERA)\n",
    "    faces = detect_faces(image)\n",
    "    print(f\"Found {len(faces)} faces\")\n",
    "    return faces\n",
    "\n",
    "\n",
    "def mark_faces(image_filename):\n",
    "    \"\"\"Mark all faces recognized in the image\"\"\"\n",
    "    image = PIL.Image.open(image_filename)\n",
    "\n",
    "    faces = detect_faces(image)\n",
    "\n",
    "    # Draw faces\n",
    "    render_data = detections_to_render_data(\n",
    "        faces, bounds_color=Colors.GREEN, line_width=3\n",
    "    )\n",
    "    render_to_image(render_data, image)\n",
    "\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://upload.wikimedia.org/wikipedia/commons/3/3d/Apollo_11_Crew.jpg\n",
    "mark_faces(\"Apollo_11_Crew.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -A \"Mozilla/5.0\" \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Isabella_L%C3%B6vin_signing_climate_law_referral.jpg/1024px-Isabella_L%C3%B6vin_signing_climate_law_referral.jpg\" -o IL.jpg\n",
    "mark_faces(\"IL.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -A \"Mozilla/5.0\" \"https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/20180610_FIFA_Friendly_Match_Austria_vs._Brazil_Miranda_850_0051.jpg/1024px-20180610_FIFA_Friendly_Match_Austria_vs._Brazil_Miranda_850_0051.jpg\" -o FIFA.jpg\n",
    "mark_faces(\"FIFA.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "217",
   "metadata": {},
   "source": [
    "# Model emulator; AIFS and AICON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "219",
   "metadata": {},
   "source": [
    "# AI Data Assimilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220",
   "metadata": {},
   "source": [
    "## Modulated sine background with 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 256\n",
    "x_grid = np.linspace(0.0, 1.0, n, endpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# \"True\" state: modulated sine\n",
    "#   y(x) = A(x) * sin(2π k x + phase) + trend\n",
    "# ----------------------------\n",
    "k = 3.0\n",
    "phase = 0.4\n",
    "A0 = 1.0\n",
    "A1 = 0.35\n",
    "A_mod_k = 1.0  # modulation wavenumber\n",
    "\n",
    "A = A0 + A1 * np.sin(2*np.pi*A_mod_k * x_grid + 0.7)\n",
    "trend = 0.15 * (x_grid - 0.5)\n",
    "x_true = A * np.sin(2*np.pi*k * x_grid + phase) + trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_grid, x_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Background xb: biased + smoothed + small noise\n",
    "# ----------------------------\n",
    "bias = 0.10\n",
    "shift = 4  # grid points, periodic shift\n",
    "x_shifted = np.roll(x_true, shift)\n",
    "\n",
    "# simple smoothing via convolution (periodic padding)\n",
    "sigma_pts = 2.0\n",
    "radius = int(np.ceil(4 * sigma_pts))\n",
    "t = np.arange(-radius, radius + 1)\n",
    "ker = np.exp(-(t**2) / (2 * sigma_pts**2))\n",
    "ker /= ker.sum()\n",
    "\n",
    "x_pad = np.r_[x_shifted[-radius:], x_shifted, x_shifted[:radius]]\n",
    "x_smooth = np.convolve(x_pad, ker, mode=\"same\")[radius:-radius]\n",
    "\n",
    "xb = x_smooth + bias + 0.03 * rng.standard_normal(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_grid, x_true)\n",
    "plt.plot(x_grid, xb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
