{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Lecture 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 2.1 Jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --version\n",
    "%pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flask\n",
    "import flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "print(site.getsitepackages())\n",
    "!ls -l {site.getsitepackages()[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 2.3 API requests using `requests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import threading\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "tasks = {}\n",
    "i = 1\n",
    "\n",
    "@app.post(\"/tasks\")\n",
    "def create():\n",
    "    global i\n",
    "    if not request.json: abort(400)\n",
    "    t = {\"id\": i, \"state\": \"created\", \"data\": request.json}\n",
    "    tasks[i] = t\n",
    "    i += 1\n",
    "    return jsonify(t), 201\n",
    "\n",
    "# This starts Flask's blocking event loop in same thread as Jupyter\n",
    "# Subsequent cells can't run until Flask stops serving\n",
    "#app.run()\n",
    "\n",
    "# Inside a Jupyter notebook then, run Flask in a background process\n",
    "# `use_reloader = False` is mandatory in a Jupyter notebook\n",
    "def run():\n",
    "    app.run(host=\"127.0.0.1\", port=5000, use_reloader=False)\n",
    "threading.Thread(target=run, daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic test using curl\n",
    "!curl -X POST http://127.0.0.1:5000/tasks -H \"Content-Type: application/json\" -d '{\"type\": \"demo\", \"params\": {\"x\": 1}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.post(\n",
    "    \"http://127.0.0.1:5000/tasks\",\n",
    "    json={\"type\": \"demo\", \"params\": {\"x\": 1}}\n",
    ")\n",
    "print(r.status_code, r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, abort, request\n",
    "import threading\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "tasks = {}\n",
    "\n",
    "i = 1\n",
    "\n",
    "@app.post(\"/tasks\")\n",
    "def create():\n",
    "    global i\n",
    "    if not request.json: abort(400)\n",
    "    t = {\"id\": i, \"state\": \"created\", \"data\": request.json}\n",
    "    tasks[i] = t\n",
    "    i += 1\n",
    "    return jsonify(t), 201\n",
    "\n",
    "@app.get(\"/tasks\")\n",
    "def list_tasks():\n",
    "    return jsonify(list(tasks.values()))\n",
    "\n",
    "@app.get(\"/tasks/<int:i>\")\n",
    "def get_task(i):\n",
    "    return jsonify(tasks[i]) if i in tasks else abort(404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    app.run(host=\"127.0.0.1\", port=5000, use_reloader=False)\n",
    "threading.Thread(target=run, daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"http://127.0.0.1:5000/tasks\")\n",
    "print(r.status_code, r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.post(\n",
    "    \"http://127.0.0.1:5000/tasks\",\n",
    "    json={\"type\": \"demo\", \"params\": {\"x\": 1}}\n",
    ")\n",
    "print(r.status_code, r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.post(\n",
    "    \"http://127.0.0.1:5000/tasks\",\n",
    "    json={\"type\": \"demo\", \"params\": {\"x\": 1}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.post(\n",
    "    \"http://127.0.0.1:5000/tasks\",\n",
    "    json={\"type\": \"demo\", \"params\": {\"x\": 1}}\n",
    ").status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(\"http://127.0.0.1:5000/tasks\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(\"http://127.0.0.1:5000/tasks/2\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Lecture 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3.2 ecCodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eccodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grib_ls -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eccodes.codes_get_api_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Read GRIB2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find .. -name \"*.grib2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "grib_file = \"../e-ai_ml2/course/code/code03/ifs_2t.grib2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(grib_file, \"rb\") as f:\n",
    "    while True:\n",
    "        gid = eccodes.codes_grib_new_from_file(f)\n",
    "        if gid is None: break\n",
    "\n",
    "        short = eccodes.codes_get(gid, \"shortName\")\n",
    "        level = eccodes.codes_get(gid, \"level\")\n",
    "        size  = eccodes.codes_get_size(gid, \"values\")\n",
    "\n",
    "        print(short, level, size)\n",
    "\n",
    "        eccodes.codes_release(gid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Download GRIB2 file from ECMWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecmwf.opendata import Client\n",
    "\n",
    "client = Client(\n",
    "    source = \"ecmwf\",\n",
    "    model = \"ifs\",\n",
    ")\n",
    "\n",
    "client.retrieve(\n",
    "    time = 0,\n",
    "    type = \"fc\",\n",
    "    step = 24,\n",
    "    param = [\"2t\", \"msl\"],\n",
    "    target = \"ifs_2t.grib2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.grib2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Download from DWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "base_url = \"http://opendata.dwd.de/weather/nwp/icon/grib/00/t_2m/\"\n",
    "now = datetime.datetime.now(datetime.UTC)\n",
    "filename = f\"icon_global_icosahedral_single-level_{now:%Y%m%d}00_000_T_2M.grib2.bz2\"\n",
    "url = base_url + filename\n",
    "grib_filename = filename[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "wget.download(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "\n",
    "with bz2.open(filename, \"rb\") as f_in, open(grib_filename, \"wb\") as f_out:\n",
    "    f_out.write(f_in.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.grib2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eccodes\n",
    "with open(grib_filename, \"rb\") as f:\n",
    "    while True:\n",
    "        gid = eccodes.codes_grib_new_from_file(f)\n",
    "        if gid is None: break\n",
    "\n",
    "        short = eccodes.codes_get(gid, \"shortName\")\n",
    "        level = eccodes.codes_get(gid, \"level\")\n",
    "        size  = eccodes.codes_get_size(gid, \"values\")\n",
    "\n",
    "        print(short, level, size)\n",
    "\n",
    "        eccodes.codes_release(gid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Extract and list metadata keys from a GRIB file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eccodes\n",
    "with open(grib_filename, \"rb\") as f:\n",
    "    while True:\n",
    "        gid = eccodes.codes_grib_new_from_file(f)\n",
    "        if gid is None: break\n",
    "\n",
    "        key_iterator = eccodes.codes_keys_iterator_new(gid)\n",
    "        keys = []\n",
    "\n",
    "        while eccodes.codes_keys_iterator_next(key_iterator):\n",
    "            keyname = eccodes.codes_keys_iterator_get_name(key_iterator)\n",
    "            if keyname not in ['section2Padding', 'codedValues', 'values']:\n",
    "                value = eccodes.codes_get_string(gid, keyname)\n",
    "            keys.append((keyname, value))\n",
    "\n",
    "        eccodes.codes_release(gid)\n",
    "\n",
    "        for key, value in keys:\n",
    "              print(f\"Key: {key:40} Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eccodes\n",
    "with open(grib_file, \"rb\") as f:\n",
    "    while True:\n",
    "        gid = eccodes.codes_grib_new_from_file(f)\n",
    "        if gid is None: break\n",
    "\n",
    "        key_iterator = eccodes.codes_keys_iterator_new(gid)\n",
    "        keys = []\n",
    "\n",
    "        while eccodes.codes_keys_iterator_next(key_iterator):\n",
    "            keyname = eccodes.codes_keys_iterator_get_name(key_iterator)\n",
    "            if keyname not in ['section2Padding', 'codedValues', 'values']:\n",
    "                value = eccodes.codes_get_string(gid, keyname)\n",
    "            keys.append((keyname, value))\n",
    "\n",
    "        eccodes.codes_release(gid)\n",
    "\n",
    "        for key, value in keys:\n",
    "              print(f\"Key: {key:40} Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cartopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(grib_file, \"rb\") as f:\n",
    "    # First message is pressure\n",
    "    gid = eccodes.codes_grib_new_from_file(f)\n",
    "\n",
    "nx = eccodes.codes_get(gid, \"Ni\")\n",
    "ny = eccodes.codes_get(gid, \"Nj\")\n",
    "values = eccodes.codes_get_array(gid, \"values\")\n",
    "field = values.reshape(ny, nx)\n",
    "\n",
    "plt.figure(figsize=(7, 3.5))\n",
    "plt.imshow(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(grib_file, \"rb\") as f:\n",
    "    # Run twice to get the second message (T2m)\n",
    "    gid = eccodes.codes_grib_new_from_file(f)\n",
    "    gid = eccodes.codes_grib_new_from_file(f)\n",
    "\n",
    "nx = eccodes.codes_get(gid, \"Ni\")\n",
    "ny = eccodes.codes_get(gid, \"Nj\")\n",
    "values = eccodes.codes_get_array(gid, \"values\")\n",
    "field = values.reshape(ny, nx)\n",
    "\n",
    "plt.figure(figsize=(7, 3.5))\n",
    "plt.imshow(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "ax.coastlines()\n",
    "ax.add_feature(cfeature.BORDERS)\n",
    "\n",
    "lats   = eccodes.codes_get_array(gid, \"latitudes\")\n",
    "lons   = eccodes.codes_get_array(gid, \"longitudes\")\n",
    "lat   = lats.reshape(ny, nx)\n",
    "lon   = lons.reshape(ny, nx)\n",
    "\n",
    "ax.pcolormesh(lon, lat, field, transform=ccrs.PlateCarree(), cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "\n",
    "def load_grib(file, var):\n",
    "    \"\"\"Loads specified variable from GRIB file.\"\"\"\n",
    "    with open(file, 'rb') as f:\n",
    "        while (gid := eccodes.codes_grib_new_from_file(f)) is not None:\n",
    "            if eccodes.codes_get(gid, \"shortName\") == var:\n",
    "                vals = eccodes.codes_get_array(gid, \"values\")\n",
    "                eccodes.codes_release(gid)\n",
    "                return vals\n",
    "            eccodes.codes_release(gid)\n",
    "    return None\n",
    "\n",
    "def interpolate_to_grid(lat, lon, t2m, bbox, grid_res=0.25):\n",
    "    \"\"\"Interpolates T2M data onto a regular lat/lon grid.\"\"\"\n",
    "    latmin, latmax, lonmin, lonmax = bbox\n",
    "\n",
    "    # Define a smooth regular grid\n",
    "    grid_lat = np.arange(latmin, latmax, grid_res)\n",
    "    grid_lon = np.arange(lonmin, lonmax, grid_res)\n",
    "    lon_grid, lat_grid = np.meshgrid(grid_lon, grid_lat)\n",
    "\n",
    "    points = np.column_stack((lon.ravel(), lat.ravel()))\n",
    "    values = t2m.ravel()\n",
    "    xi = np.column_stack((lon_grid.ravel(), lat_grid.ravel()))\n",
    "    t2m_grid = griddata(points, values, xi, method='cubic')\n",
    "    t2m_grid = t2m_grid.reshape(lon_grid.shape)\n",
    "    \n",
    "    return lon_grid, lat_grid, t2m_grid\n",
    "\n",
    "\n",
    "def plot_t2m_grid(lat, lon, t2m, bbox, title, fname):\n",
    "    \"\"\"Plots interpolated 2m temperature as a smooth heatmap.\"\"\"\n",
    "    lon_grid, lat_grid, t2m_grid = interpolate_to_grid(lat, lon, t2m, bbox)\n",
    "\n",
    "    # Set reasonable aspect ratio based on bounding box size\n",
    "    lon_range = bbox[3] - bbox[2]\n",
    "    lat_range = bbox[1] - bbox[0]\n",
    "    aspect_ratio = lon_range / lat_range\n",
    "    figsize = (10, max(5, 10 / aspect_ratio))  # Maintain consistent width & prevent extreme height\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.set_extent([bbox[2], bbox[3], bbox[0], bbox[1]])\n",
    "    ax.add_feature(cfeature.LAND, edgecolor='black')\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "\n",
    "    # Use smooth interpolation and correct aspect ratio\n",
    "    img = ax.imshow(t2m_grid, extent=[bbox[2], bbox[3], bbox[0], bbox[1]], origin='lower',\n",
    "                    cmap='jet', transform=ccrs.PlateCarree(), aspect='auto', interpolation='bicubic')\n",
    "\n",
    "    plt.colorbar(img, label=\"Temperature (K)\")\n",
    "    plt.title(title)\n",
    "    plt.savefig(fname, dpi=200, bbox_inches='tight')  # Reduce DPI for smaller file size\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Load data\n",
    "lat = load_grib(\"../e-ai_ml2/course/code/code03/icon_lat.grib\", \"tlat\")\n",
    "lon = load_grib(\"../e-ai_ml2/course/code/code03/icon_lon.grib\", \"tlon\")\n",
    "t2m = load_grib(\"../e-ai_ml2/course/code/code03/icon_t2m.grib\", \"2t\")\n",
    "\n",
    "# Plot interpolated global and Germany views\n",
    "plot_t2m_grid(lat, lon, t2m, (-90, 90, -180, 180), \"Interpolated Global 2m Temperature\", \"icon_t2m_global_interp.png\")\n",
    "plot_t2m_grid(lat, lon, t2m, (47, 55, 5, 15), \"Interpolated 2m Temperature over Germany\", \"icon_t2m_germany_interp.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3.3 Accessing SYNOP observation files from NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ../e-ai_ml2 -name \"*.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install netCDF4\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "filename = \"../e-ai_ml2/course/code/code03/synop.nc\"\n",
    "\n",
    "ncfile = Dataset(filename, \"r\")\n",
    "\n",
    "lats = ncfile.variables[\"MLAH\"][:]\n",
    "lons = ncfile.variables[\"MLOH\"][:]\n",
    "temps = ncfile.variables[\"MTDBT\"][:]\n",
    "\n",
    "lats = np.array(lats)\n",
    "lons = np.array(lons)\n",
    "temps = np.array(temps)\n",
    "\n",
    "ncfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=1e+20\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "#projections = [[ccrs.PlateCarree(), \"PlateCarree\"]]\n",
    "projections=[[ccrs.PlateCarree(), \"PlateCarree\"], \n",
    "                                  [ccrs.TransverseMercator(), \"TransverseMercator\"],\n",
    "                                  [ccrs.Mercator(), \"Mercator\"],\n",
    "                                  [ccrs.EuroPP(), \"EuroPP\"],\n",
    "                                  [ccrs.Geostationary(), \"Geostationary\"],\n",
    "                                  [ccrs.Stereographic(), \"Stereographic\"]]\n",
    "# Filter out large missing values\n",
    "valid_mask = (temps < threshold) & np.isfinite(temps)\n",
    "lats, lons, temps = lats[valid_mask], lons[valid_mask], temps[valid_mask]\n",
    "\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "for projection in projections:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={'projection': projection[0]})\n",
    "        scatter = ax.scatter(lons, lats, c=temps, cmap='jet', s=5, alpha=0.7, transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Add map features\n",
    "        ax.coastlines()\n",
    "        ax.add_feature(cfeature.BORDERS, edgecolor='gray')\n",
    "        ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "\n",
    "        # Add colorbar with better spacing\n",
    "        cbar = plt.colorbar(scatter, ax=ax, fraction=0.04, pad=0.08)  \n",
    "        cbar.set_label(\"Temperature (K)\")\n",
    "\n",
    "        # Set title\n",
    "        plt.title(\"Temperature Observations on Map in Projection \" + projection[1])\n",
    "\n",
    "        # Save and show the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3.4 AIREP feedback files in NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "airep_file = \"../e-ai_ml2/course/code/code03/monAIREP.nc\"\n",
    "\n",
    "ncfile = Dataset(airep_file, \"r\")\n",
    "\n",
    "nc = 1\n",
    "for varname in ncfile.variables.keys():\n",
    "    var = ncfile.variables[varname]\n",
    "    description = getattr(var, \"longname\", \"N/A\")\n",
    "    dims = [len(ncfile.dimensions[dim]) for dim in var.dimensions]\n",
    "    shape1 = dims[0] if len (dims) > 0 else \"\"\n",
    "    shape2 = dims[1] if len (dims) > 1 else \"\"\n",
    "    print (\"{:<4} {:40} {:>10} {:>10} {:30}\".format(nc, varname, shape1, shape2, description))\n",
    "    if nc % 10 == 0:\n",
    "        print(\"-\" * 110)\n",
    "    nc += 1\n",
    "\n",
    "ncfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read header-level variables\n",
    "#ncfile = Dataset(airep_file, \"r\")\n",
    "lat = ncfile.variables[\"lat\"][:]\n",
    "lon = ncfile.variables[\"lon\"][:]\n",
    "\n",
    "# Body-level variables\n",
    "varno_all = ncfile.variables[\"varno\"][:]\n",
    "obs_all = ncfile.variables[\"obs\"][:]\n",
    "l_body = ncfile.variables[\"l_body\"][:]\n",
    "\n",
    "# Expand lat/lon to match body-level observations\n",
    "ni = len(l_body)\n",
    "ie = np.repeat(range(0, ni), l_body)  # Map each body entry to its header index\n",
    "\n",
    "# varno == 2 is upper air temperature\n",
    "idx = np.where(varno_all == 2)[0]\n",
    "\n",
    "# Filter lat, lon, obs\n",
    "lat_filtered = lat[ie[idx]]\n",
    "lon_filtered = lon[ie[idx]]\n",
    "obs_filtered = obs_all[idx]\n",
    "\n",
    "var = \"level\"\n",
    "var_data = ncfile.variables[var][:]\n",
    "\n",
    "print(var_data.shape[0], len(varno_all))\n",
    "\n",
    "extra_data = var_data[idx]\n",
    "lats, lons, obs = lat_filtered, lon_filtered, obs_filtered\n",
    "heights = extra_data\n",
    "\n",
    "threshold=1e+20\n",
    "\n",
    "print(len(lats), \"Latitudes:\", lats[:5])\n",
    "print(len(lons), \"Longitudes:\", lons[:5])\n",
    "print(len(obs), \"Observations:\", obs[:5])\n",
    "if heights is not None:\n",
    "    print(len(heights), \"Heights:\", heights[:5])\n",
    "\n",
    "valid_mask = (obs < threshold) & np.isfinite(obs)\n",
    "lats, lons, obs = lats[valid_mask], lons[valid_mask], obs[valid_mask]\n",
    "\n",
    "# Keep only temperatures between -30°C and 40°C (243.15K to 313.15K)\n",
    "temp_min, temp_max = 180, 320\n",
    "physical_mask = (obs >= temp_min) & (obs <= temp_max)\n",
    "\n",
    "lats_filtered, lons_filtered, obs_filtered = lats[physical_mask], lons[physical_mask], obs[physical_mask]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "scatter = ax.scatter(lons_filtered, lats_filtered, c=obs_filtered, cmap='jet', s=2, alpha=0.7, transform=ccrs.PlateCarree())\n",
    "\n",
    "ax.coastlines()\n",
    "ax.add_feature(cfeature.BORDERS, edgecolor='gray')\n",
    "ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "\n",
    "# Ensure the colorbar does not exceed figure height\n",
    "cbar = fig.colorbar(scatter, ax=ax, orientation='vertical', fraction=0.04, pad=0.08, shrink=0.8)\n",
    "cbar.set_label(\"Temperature (K)\")\n",
    "\n",
    "plt.title(\"AIREP Observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## GPU access in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((40000,40000),device=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "y = torch.matmul(x, x)\n",
    "torch.mps.synchronize()\n",
    "print(\"Time = \", round(time.time()-t0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 40000\n",
    "x0 = torch.rand((n, n), device=\"cpu\")\n",
    "x1 = torch.rand((n, n), device=\"cpu\")\n",
    "t0 = time.time()\n",
    "y = torch.matmul(x0, x1)\n",
    "print(\"Time = \", round(time.time() - t0, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "### Mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "## AI and ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "### Torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.tensor([2., 3.], requires_grad=True)\n",
    "y = x[0]**2 + x[1]**2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# nn.Module is the base class for models and layers\n",
    "# Holds parameters (weights and biases)\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Layer 1: 1 -> 16\n",
    "        self.fc1 = nn.Linear(1,16)\n",
    "        \n",
    "        # Non-linear activation function (ReLU in this case)\n",
    "        self.relu = nn.reLU()\n",
    "        \n",
    "        # Layer 2: 16 -> 1\n",
    "        self.fc2 = nn.Linear(16,1)\n",
    "\n",
    "    # Calling `model(x)` runs the model's `forward()` method\n",
    "    # Forward pass computes predictions from inputs (x)\n",
    "    # Builds the autograd graph (if grads enables on x)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "Learning a sine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input values x\n",
    "x = np.linspace(0, 2*np.pi, 1000)\n",
    "\n",
    "# Compute labels y = sin(x)\n",
    "y = np.sin(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset construction\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "x_t = torch.tensor(x).float().unsqueeze(1)\n",
    "y_t = torch.tensor(y).float().unsqueeze(1)\n",
    "\n",
    "data = TensorDataset(x_t, y_t)\n",
    "loader = DataLoader(data,\n",
    "                    batch_size=32,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and training loop\n",
    "\n",
    "# Learn non-linear mapping x -> \\hat{y}\n",
    "# Input: scalar x\n",
    "# Output: scalar \\hat{y}\n",
    "\n",
    "# Model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1,16), nn.ReLU(),\n",
    "    nn.Linear(16,16), nn.ReLU(),\n",
    "    nn.Linear(16,1)\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Optimiser\n",
    "opt = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr = 0.01\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "#     - Compare \\hat{y} and y\n",
    "#     - Minimise prediction error\n",
    "#     - Update model parameters\n",
    "for x_b, y_b in loader:\n",
    "    \n",
    "    # Zero the gradients from the previous iteration\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # Forward pass of the model to get predictions\n",
    "    y_p = model(x_b)\n",
    "\n",
    "    # Update loss given predictions y_p\n",
    "    loss = loss_fn(y_p, y_b)\n",
    "\n",
    "    # Backpropagation - compute gradients of loss wrt parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Optimiser - update parameters (weights and biases) in-place\n",
    "    # given the gradients\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
